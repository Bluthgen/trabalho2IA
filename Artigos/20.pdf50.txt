IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

249

Multiobjective Evolutionary Optimization of Type-2 Fuzzy Rule-Based Systems for Financial Data Classification
Michela Antonelli, Dario Bernardo, Hani Hagras, Fellow, IEEE, and Francesco Marcelloni, Member, IEEE

Abstract--Classification techniques are becoming essential in the financial world for reducing risks and possible disasters. Managers are interested in not only high accuracy, but in interpretability and transparency as well. It is widely accepted now that the comprehension of how inputs and outputs are related to each other is crucial for taking operative and strategic decisions. Furthermore, inputs are often affected by contextual factors and characterized by a high level of uncertainty. In addition, financial data are usually highly skewed toward the majority class. With the aim of achieving high accuracies, preserving the interpretability, and managing uncertain and unbalanced data, this paper presents a novel method to deal with financial data classification by adopting type-2 fuzzy rule-based classifiers (FRBCs) generated from data by a multiobjective evolutionary algorithm (MOEA). The classifiers employ an approach, denoted as scaled dominance, for defining rule weights in such a way to help minority classes to be correctly classified. In particular, we have extended PAES-RCS, an MOEA-based approach to learn concurrently the rule and data bases of FRBCs, for managing both interval type-2 fuzzy sets and unbalanced datasets. To the best of our knowledge, this is the first work that generates type-2 FRBCs by concurrently maximizing accuracy and minimizing the number of rules and the rule length with the objective of producing interpretable models of real-world skewed and incomplete financial datasets. The rule bases are generated by exploiting a rule and condition selection (RCS) approach, which selects a reduced number of rules from a heuristically generated rule base and a reduced number of conditions for each selected rule during the evolutionary process. The weight associated with each rule is scaled by the scaled dominance approach on the fuzzy frequency of the output class, in order to give a higher weight to the minority class. As regards the data base learning, the membership function parameters of the interval type-2 fuzzy sets used in the rules are learned concurrently to the application of RCS. Unbalanced datasets are managed by using, in addition to complexity, selectivity and specificity as objectives of the MOEA rather than only the classification rate. We tested our approach, named IT2-PAES-RCS, on 11 financial datasets and compared our results with the ones obtained by the original PAES-RCS with three objectives and with and without scaled dominance, the FRBCs, fuzzy association rule-based
Manuscript received June 26, 2015; revised September 18, 2015 and January 21, 2016; accepted April 20, 2016. Date of publication June 8, 2016; date of current version March 29, 2017.
M. Antonelli was with the Dipartimento di Ingegneria dell'Informazione, University of Pisa, Pisa I-56100, Italy. She is now with the Centre for Medical Image Computing, University College London, London WC1E 6BT, U.K (e-mail: michela.antonelli@iet.unipi.it).
D. Bernardo and H. Hagras are with the Computational Intelligence Centre, School of Computer Science and Electronic Engineering University of Essex, Colchester CO43SQ, U.K. (e-mail: dariob@hotmail.com; hani@essex.ac.uk).
F. Marcelloni is with the Dipartimento di Ingegneria dell'Informazione, University of Pisa, Pisa I-56100, Italy (e-mail: francesco.marcelloni@iet.unipi.it).
Digital Object Identifier 10.1109/TFUZZ.2016.2578341

classification model for high-dimensional dataset (FARC-HD) and fuzzy unordered rules induction algorithm (FURIA), the classical C4.5 decision tree algorithm, and its cost-sensitive version. Using nonparametric statistical tests, we will show that IT2-PAES-RCS generates FRBCs with, on average, accuracy statistically comparable with and complexity lower than the ones generated by the two versions of the original PAES-RCS. Further, the FRBCs generated by FARC-HD and FURIA and the decision trees computed by C4.5 and its cost-sensitive version, despite the highest complexity, result to be less accurate than the FRBCs generated by IT2-PAES-RCS. Finally, we will highlight how these FRBCs are easily interpretable by showing and discussing one of them.
Index Terms--Financial datasets, multiobjective evolutionary fuzzy systems, type-2 fuzzy rule-based classifiers, unbalanced datasets.
I. INTRODUCTION
T HE financial crisis of 2008 demonstrated that lack of good information can lead to disasters. Financial services organizations, customers, and particularly regulators quickly came to understand that clear and relevant information was key to risk reduction. Therefore, we are now witnessing ongoing efforts by regulators to ensure that firms operating in financial services generate comprehensive and comprehensible information. Superficially, the demands of regulators look burdensome. In reality, however, they provide an opportunity for organizations to improve their strategic and operational activities through risk reduction based on well-managed information [1].
Machine learning in financial applications differs from other domains in how the quality of a model is assessed. Whereas in most applications, "accuracy of prediction" is often the only metric used, in financial applications, interpretability and transparency are also important and sometimes a requirement. Within financial applications, the accuracy of the model is not the only crucial issue. There is a growing interest in having high levels of model transparency, which is the ability to provide a clear and understandable explanation of the output result. If advanced analytical techniques are used, there is now an obligation to manage the whole process of creating and using the resulting models. It is no longer enough to create a model, deploy it into production, and leave it unattended without any oversight. A set of capabilities and processes are required to ensure that every aspect of model creation, deployment, and performance is well understood, managed, and documented. This implies additional technology infrastructure and methods, since in large firms, the

1063-6706 Š 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications standards/publications/rights/index.html for more information.

250

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

number of models in use might be measured in the thousands. This represents a significant shift to much greater sophistication [1]. Another reason why it is important that we can understand models is trust. A system that can explain why a certain decision was taken is more trustworthy in the eyes of a layman user. This need for transparency is reflected in legislation that forces financial institutions to disclose the reasoning behind their financial decisions and models. Left unchecked, inevitably, there will be rogue models that cause financial harm and breach regulatory requirements [2]. Furthermore, transparency of a model is important because it allows users to understand data association by observing why a specific decision has been taken. This process helps users to drill-down into their data, understand it, and extract some useful knowledge that could be a competitive advantage in the market. Ultimately, a transparent model can become not only a tool for foresight and prediction, but for analysis and domain knowledge extraction as well. As it is often the case, managers in finance face two conflicting demands. On the one hand, they need to employ ever more powerful analytical techniques to remain competitive, while, on the other hand, the models they use must be transparent and relatively easy to explain [1]­[3].
Neural networks, Bayesian networks, and support vector machines are all considered "black box." This adjective is applied to systems that, for a given input, are able to output a class label, but without providing a clear explanation of the decision process. Logistic regression can provide some statistic correlations between the inputs and the output, but this is not enough to understand why, for a given input, a given label was chosen, or to gain a deep insight of either the model or the data. On the other hand, "white box" models usually refer to rule-based systems that are able to provide an insight of the data on which the models have been trained and an explanation of the decision process through their rules. Decision trees can translate their internal state into a set of rules and, like any other rule-based system, are able to provide transparency. Nevertheless, in complex real-world applications, such as in the financial domain, the number of generated rules can explode. It is debatable that a rule base containing thousands of rules can be considered an understandable and transparent model. Decision trees [4]­[6] and random forests [7] produce associations among sets of data, which are selected to optimize the classification problem. Thus, the produced associations could be meaningless in the context of profiling and knowledge extraction.
Fuzzy logic extends the concepts of association rule learning by extending the rule antecedent sets to fuzzy concepts. This technique, in conjunction with genetic and evolutionary algorithms, is a powerful approach for creating accurate and interpretable models. Studies such as [8]­[11] have shown that accuracy and interpretability are in a tradeoff, and it is necessary to sacrifice one in order to increase the other. It is difficult to define to which extent accuracy or interpretability can be sacrificed in order to gain in the other. Usually, different applications and specific situations have different requirements. Multiobjective genetic algorithms are able to provide an evolution through the two competitive objectives: accuracy and interpretability [12], [13]. Such evolutionary algorithms generate a set of solutions, also known as Pareto front, that optimize both objectives at

different levels. This feature gives the ability to easily identify the desired level of complexity/accuracy for the specific application. However, the vast majority of fuzzy systems employ the type-1 fuzzy sets, which cannot directly handle the high levels of uncertainty present in financial applications. Indeed, type-1 fuzzy sets are crisp and precise (i.e., their membership functions are supposed to be perfectly known) and do not allow for any uncertainty about membership values, which is a liability for their use. A type-2 fuzzy set is characterized by a fuzzy membership function, i.e., the membership value for each element of this set is itself a fuzzy set defined on the universe [0,1] [14]. The membership functions of the type-2 fuzzy sets are 3-D and include a footprint of uncertainty. The third dimension and the footprint of uncertainty provide additional degrees of freedom that make it possible to directly model and handle the high level of uncertainty affecting the inputs in financial applications. In addition, it should be noted that using type-2 fuzzy sets to represent the system inputs can result in reduction of the fuzzy classifier rule base and complexity (as it will be shown in Section IV) when compared with using type-1 fuzzy sets. Indeed, the footprint of uncertainty, which characterizes the type-2 fuzzy sets, lets us cover the same range as type-1 fuzzy sets with a smaller number of labels: Of course, the rule reduction will be greater when the number of inputs increases [14].
Previous works have already employed type-2 fuzzy classifiers in financial domain [15]­[17] and have shown how these systems outperform their type-1 versions and other state-ofthe-art classifiers. However, to date, most of the type-2 fuzzy systems reported in the literature have been generated from data by optimizing only the accuracy, while neglecting the complexity [17]­[23]. This aspect is of major importance to the financial domain since offering compact fuzzy classifiers with the same accuracy as their counterparts will help to realize transparent and easy to understand models, which are becoming essential requirements especially after the recent economic crisis.
In financial applications, as in many real-world problems, the data present challenges that are not often found in traditional academic datasets. Some of these are: size, noise, sparsity, and uncertainty. Furthermore, in the vast majority of financial applications, data are highly unbalanced [24]. For example, in credit card applications, the number of good customers is much higher than that of bad customers, and in fraud detection, the majority of the data is normal transactions with only a few fraudulent transactions. Most classifiers designed for minimizing the global error rate perform poorly on unbalanced datasets, because they misclassify most of the data belonging to the class with few examples. To tackle this problem, preprocessing techniques like undersampling or oversampling are usually applied, but both of them present problems. On the one hand, undersampling techniques may increment the noise, since they could eliminate some important patterns. On the other hand, oversampling techniques may add noise for the original input data or violate the inherent geometrical structure of the minority and majority classes. Hence, in financial applications, it is not desirable to preprocess or sample the data, as this could cause problems. Thus, there is a need for predictive analytics techniques that can handle unbalanced financial datasets to give accurate and interpretable financial models.

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

251

In this paper, with the aim of dealing with uncertain and unbalanced data and generating accurate and interpretable classifiers, we employ PAES-RCS [25], [26], a multiobjective evolutionary algorithm (MOEA)-based approach to learn concurrently the rule and data bases of fuzzy rule-based classifiers (FRBCs). In PAES-RCS, the learning process is performed by selecting a set of rules from an initial rule base and a set of conditions for each selected rule. This scheme is denoted as rule and condition selection (RCS). During the multiobjective evolutionary process, PAES-RCS generates the rule bases of the classifiers by using the RCS approach and concurrently learns the membership function parameters of the linguistic values used in the rules. The original PAES-RCS is extended so as to manage interval type-2 (IT2) fuzzy sets and unbalanced datasets. We denote this extension as IT2-PAES-RCS in the following. We modified both the inference mechanism and the evolutionary process for coping with the IT2 fuzzy sets. Further, we adopted three objectives, namely false positive rate (FPR), true positive rate (TPR), and complexity. In our previous works [27], we have verified that the use of FPR and TPR as objectives of the evolutionary optimization process has proved to be very effective in managing unbalanced datasets. Indeed, one of the main strengths of IT2-PAES-RCS is that it can be applied to unbalanced datasets without any rebalancing.
We tested IT2-PAES-RCS on 11 financial datasets and compared the results with the ones obtained by the original PAES-RCS, employing FPR and TPR as objectives, with (PAES-RCS-SD) and without scaled dominance, the FRBCs fuzzy association rule-based classification model for highdimensional dataset (FARC-HD) [28] and fuzzy unordered rules induction algorithm (FURIA) [29], the classical C4.5 decision tree algorithm [30], and its cost-sensitive version (C4.5-CS) [31]. Using nonparametric statistical tests, we will show that IT2-PAES-RCS generates FRBCs with accuracy statistically comparable with the ones generated by PAES-RCS and PAESRCS-SD, employing a lower number of rules and a lower number of conditions in the antecedent of the rules. The FRBCs generated by IT2-PAES-RCS result, therefore, to be less complex and more interpretable. Further, the FRBCs generated by FARC-HD and FURIA, and the decision trees computed by C4.5 and its cost-sensitive version, despite the lowest interpretability, result to be less accurate than the solutions generated by IT2-PAES-RCS.
This paper is organized as follows. In Section II, we provide a basic description of FRBCs based on IT2 fuzzy sets and introduce some notations. Section III shows the proposed MOEAbased learning approach and includes the details of the initial rule base generation technique, of the chromosome coding and mating operators, and of the adopted MOEA. In Section IV, we illustrate the experimental results, and in Section V, we draw some final conclusion.
II. INTERVAL TYPE-2 FUZZY RULE-BASED CLASSIFIER
Object classification consists of assigning a class Cj from a predefined set {C1 , . . . , CK } of classes to an object. Each object is considered as an F-dimensional point in a feature space F . Let X = {X1 , . . . , XF } be the set of features

Fig. 1. Example of IT2 fuzzy partitions with Tf = 5 IT2 fuzzy sets (the thick and thin lines represent the upper and lower membership functions,
respectively).

and Uf , f = 1, . . . , F , be the universe of the fth feature. Let P~f = {A~f,1 , , . . . , A~f,Tf }, f = 1, . . . F , be a fuzzy partition with Tf IT2 fuzzy sets of the universe Uf . We recall that an IT2 fuzzy set A~ is characterized by a fuzzy membership
function A~(x), that is, the membership value for each element of this set is a fuzzy set [32]. The membership functions of IT2
fuzzy sets include a footprint of uncertainty, which provides
additional degrees of freedom that make it possible to directly
model and handle uncertainties. In the IT2 fuzzy sets, all the 3-D
values are equal to 1. More formally, the membership function A~(x) of an IT2 fuzzy set A~ is defined as

A~ (x) =
x X

1/u /x u [A~ (x), Ż A~ (x) ]

(1)

where ŻA~(x) and A~(x) represent, respectively, the upper and lower membership functions of the IT2 fuzzy set A~. In this pa-

per, we use triangular membership functions defined by three

points (a, b, c), where a and c correspond to the endpoints of

the support and b to the core. We build the IT2 fuzzy sets by

using the following procedure. First, we define the upper tri-

angular (aŻf,j , Żbf

membership functions ,j , cŻf,j ). Then, the left

ŻA~(x) through endpoints af,j

the three points of the supports

of the lower membership functions A~f (x) are computed as

midpoints

aŻ f , j +Żbf , j 2

between the left endpoints aŻf,j

of the

supports of the upper membership functions ŻA~f (x) and their

cores Żbf,j . Similarly, the right endpoints cf,j of the supports

of the lower membership functions A~f (x) correspond to the

mid-points

Żbf , j

+ cŻf , j 2

between the right endpoints cŻf,j

of the sup-

ports of the upper membership functions ŻA~f (x) and the cores

Żbf,j . It follows that af,j = cf,j-1 , for j = 2, . . . , Tf . The

cores bf,j coincide with the cores Żbf,j . Fig. 1 shows an example

of IT2 fuzzy partition with Tf = 5. Here, the upper member-

ship functions (thick lines) are obtained by defining a uniform

Ruspini partition with triangular membership functions on the

universe Uf .

252

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

The mth rule Rm (m = 1, . . . , M ) of an IT2 FRBC is typically expressed as
Rm : IF X1 is A~1,jm, 1 and . . . and XF is A~F,jm, F

THEN Y is Cjm with RWm

(2)

where Y is the classifier output, Cjm is the class label associated with the mth rule, jm,f  [1, Tf ] identifies the index of the IT2 fuzzy set (among the Tf IT2 fuzzy sets of the partition P~f ),
which has been selected for Xf in rule Rm , and RWm is the
rule weight, i.e., a certainty degree of the classification in the

class Cjm for a pattern that fires the antecedent of the rule. Let T = {(x1 , y1 ), . . . , (xN , yN )} be a training set com-
posed of N input-output (xt , yt ) pairs, with xt = [xt,1 , . . . , xt,F ]  F and yt  {C1 , . . . , CK }. The strength of activation wm (xt ) (matching degree of the rule with the input) of the
rule Rm is calculated as

wm

(xt )

=

wm

(xt )

+ 2

wŻm

(xt )

(3)

where wm (xt ) =

F f =1

A~f

(xt,f

)

and

wŻm (xt )

=

F f =1

ŻA~f

(xt,f ) are the lower and upper bounds of the strength of acti-

vation computed, respectively, on the lower and upper member-

ship functions. To take the "don't care" condition into account, a particular IT2 fuzzy set A~f,0 (f = 1, . . . , F ) is added to all the F partitions P~f . This fuzzy set is characterized by both the
lower and upper membership functions equal to 1 on the overall universe. This means that the condition "Xf is A~f,0 " does
not affect the computation of the strength of activation. In other

words, for the specific rule, the variable Xf is not taken into account and, therefore, can be removed. The terms A~f,0 , there-
fore, allow generating rules, which contain only a subset of the

input variables, thus reducing the total rule length (TRL) and

consequently increasing the interpretability of the rules.

As we have pointed out in Section I, financial data are usually

highly unbalanced. To give minority class a fair chance when

competing with majority class, we adopted a new approach to

calculate the rule weight that takes the fuzzy frequency of the

class into account. The approach is called "scaled dominance"

and has been introduced in [33]­[35]. In the literature, fuzzy

rule weights are traditionally calculated as fuzzy extension of the

confidence and support. Confidence and support are data mining

metrics used in association rule learning. These metrics, in fuzzy

rule-based systems, are extended by using fuzzy strength instead

of crisp counting of the item sets. The confidence and support extensions used in this paper exploit a scaled version wms of the matching degree. For a given rule Rm , having a consequent
class Cjm , we scale the matching degree of the rule by dividing the upper and lower bounds of the strengths of activation by the
sum of, respectively, the upper wŻl (xt ) and lower wl(xt ) bounds of the strengths of activation of all the rules Rl, which have Cjm as the consequent class. The scaled upper and lower bounds are,

therefore, computed as follows:

wŻms (xt ) =

wŻm (xt ) l,out= Cj m wŻl (xt )

(4)

wsm (xt ) =

wm (xt ) l,out= Cjm w

l

(xt )

.

(5)

In IT2 fuzzy rule-based systems, confidence and support of a rule are determined from the strength of activation and, therefore, defined by upper and lower bounds. From (4) and (5), we derive the following scaled upper and lower bounds of the confidence:

cŻms (Antm  Cjm ) =

xt Cj m wŻms (xt )

M m=1

wŻms

(xt )

(6)

csm (Antm  Cjm ) =

xt Cj m wsm (xt )

M m=1

wsm

(xt )

(7)

where M is the number of rules in the rule base, and Antm is the antecedent of Rm . The confidence can be viewed as a numerical approximation of the conditional probability P (Cjm |Antm ). The scaled upper and lower bounds of the support are defined
as

sŻsm (Antm  Cjm ) =

xt Cj m wŻms (xt ) M

(8)

ssm (Antm  Cjm ) =

xt C j m

wsm

(xt ) .

M

(9)

The support can be viewed as a measure of the coverage of
training patterns performed by Rm . The rule weight is then calculated as product of the scaled
confidence and support. It follows that the rule weight RWm in (2) becomes a closed interval bounded by the upper RW m and RW m endpoints, calculated as

RW m = cŻsm ˇ sŻsm

(10)

RW m = csm ˇ ssm

(11)

The turn, a

calsossoecdiaitnitoenrvdalegbroeuendweidthbythtehecluapspseCr hŻjmm

will (xt )

be, and

in its lower

h m (xt ) endpoints, which are computed as follows:

hŻm (xt ) = wŻms (xt ) ˇ RW m

= wŻms (xt ) ˇ

x t C j m wŻms (xt )

M m=1

wŻms

(xt )

ˇ

x t C j m wŻms (xt ) = wŻms (xt ) ˇ

M

M

2
x t C j m wŻms (xt )

M m=1

wŻms

(xt )

h m (xt ) = wms (xt ) ˇ RW m

= wsm (xt ) ˇ

x t C j m

w

s m

(xt )

M m=1

wsm

(xt )

ˇ

x t C j m

w

s m

(xt )

=

wms (xt ) ˇ

M

M

2

x t C j m wsm (xt )

M m=1

w

s m

(xt )

.

(12) (13)

We adopt the maximum matching method as reasoning method: An input pattern is classified into the class corresponding to the rule with the maximum association degree calculated for the pattern. In the case of tie, we randomly classify the pattern. The association degree for rule Rm is computed as

hm

(xt )

=

hŻ m

(xt )

+ 2

h

m

(xt ) .

(14)

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

253

Once fixed the number Tf of IT2 fuzzy sets for each linguistic variable, we adopt an MOEA-based approach to learn rules and membership function parameters so as to generate a set of IT2 FRBCs with different tradeoffs between accuracy and rule base complexity.
III. PROPOSED THREE OBJECTIVE EVOLUTIONARY OPTIMIZATION OF INTERVAL TYPE-2 FUZZY RULE-BASED CLASSIFIERS
MOEAs have been applied in several different domains to search for optimal solutions to problems characterized by multiple performance criteria in competition with each other [36]. MOEAs do not generate a unique solution, but rather a set of equally valid solutions, where each solution tends to fulfill a criterion to a higher extent than another. Comparison between different solutions is performed by using the notion of Pareto dominance. A solution x, associated with a performance vector u, dominates a solution y, associated with a performance vector v, if and only if,  i  {1, . . . , I}, with I the number of criteria, ui performs better than, or equal to, vi and i  {1, . . . , I}, such that ui performs better than vi, where ui and vi are the ith elements of vectors u and v, respectively. The set of solutions, which are not dominated by any other possible solution, is denoted as Pareto front. The objective of any MOEA is, therefore, to search for a set of solutions that are a good approximation of the Pareto front. In the last years, in designing fuzzy rulebased systems, developers have not only considered accuracy, but also interpretability as a crucial requirement. Since accuracy and interpretability are objectives in competition with each other, MOEAs have been so extensively applied that the term multiobjective evolutionary fuzzy system has been coined to identify fuzzy rule-based systems generated by MOEAs [12], [13], [37], [38]. While the accuracy objective has been typically measured in terms of classification rate and approximation error for, respectively, classification and regression problems, a number of specific measures have been proposed for evaluating the interpretability, taking the rule base complexity and the data base integrity into account [39], [40]. A large number of contributions have been recently published under the framework of multiobjective evolutionary fuzzy systems, with application mostly to regression [41]­[58] problems. Recently, some taxonomies of the main contributions have been also introduced in [12] and [13].
In this paper, we extend PAES-RCS, a multiobjective evolutionary fuzzy system that has been recently proposed by some of the authors of this paper in [25] and [26]. PAES-RCS has proved to be very effective and efficient in classification problems [26]. The original PAES-RCS learns concurrently the rule and data bases of type-1 FRBCs by exploiting the RCS approach, which selects a reduced number of rules from a heuristically generated rule base and a reduced number of conditions for each selected rule during the evolutionary process. Thus, RCS can be considered a sort of rule learning in a search space constrained by the heuristically generated rule base. The membership function parameters of the type-1 fuzzy sets are learned concurrently to the application of RCS. This requires an appropriate chromosome coding and properly defined mating operators. In particular,

chromosome C consists of two parts (CRB , CDB ), which define the rule base and the membership function parameters of the input variables, respectively. Both crossover and mutation operators are applied to each part of the chromosome independently. The objectives used in PAES-RCS are classification rates and complexity measured in terms of the total number of antecedent conditions of the rules in the rule base.
In this paper, we extend PAES-RCS along three directions. First of all, we employ IT2 fuzzy sets rather than type-1 fuzzy sets. This has required the adoption of a different inference mechanism. Second, in order to cope with unbalanced datasets, we split the accuracy into two objectives, namely TPR and FPR. We recall that TPR and FPR coincide, respectively, with the sensitivity and the complement to 1 of the specificity. As experimented in [27] and [37] using rule learning, this approach allows achieving high accuracies when dealing with unbalanced datasets without needing to rebalance the dataset. Third, we use an approach denoted as scaled dominance, which was introduced in [33]­[35], to handle unbalanced data by trying to give minority classes a fair chance when competing with a majority class. This improvement further contributes to manage unbalanced data.
In the following subsections, we will discuss the method to generate the initial rule base and summarize the RCS approach and the membership function parameter learning used in IT2PAES-RCS.
A. Initial Rule Base Generation
We generate the initial rule base by first transforming each continuous variable into a categorical and ordered variable. Then, we apply the well-known C4.5 algorithm to the transformed dataset for generating a decision tree. Finally, we extract the initial rule base from the decision tree.
More precisely, for each continuous variable Xf , first, we generate an IT2 fuzzy partition P~f = {A~f,1 , , . . . , A~f,Tf } of Tf IT2 fuzzy sets, as shown in Fig. 1. The number Tf of IT2 fuzzy sets can be different from an input variable to another. For the sake of simplicity, in our experiments, we have used the same number of IT2 fuzzy sets for all the variables Xf . Then, we compute the -cut, with  = 0.5, of the fuzzy sets defined by the upper membership functions ŻA~f,j of the IT2 fuzzy sets A~f,j , j = 1, . . . , Tf . The corresponding contiguous intervals, shown in Fig. 2, are used to discretize the universe Uf of each variable Xf before applying the C4.5 algorithm. For simplicity, we will denote the intervals with the index of the corresponding IT2 fuzzy set, which the -cut is applied to. For instance, interval 1 denotes the interval corresponding to the -cut of the fuzzy set defined by ŻA~f,1 . Then, each input value of the input­output pairs in the training set is replaced by the interval, which contains it. Thus, the overall training set is transformed so as to contain exclusively categorical values. Finally, we apply the classical C4.5 algorithm to the transformed training set. We extract the initial rule base from the decision tree generated by the C4.5 algorithm. Rules are extracted from each path from the root to a leaf node. Each splitting criterion along a given path is logically ANDed to form the rule antecedent ("IF" part). The leaf node holds the class prediction, forming the rule

254

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

Fig. 2. Discretization of the universe Uf based on an IT2 fuzzy partition (the thick and thin lines represent the upper and lower membership functions,
respectively; the dashed lines denote the boundaries of the intervals generated
by the -cut).

Fig. 4. Fuzzy rule base extracted from the decision tree shown in Fig. 3.

Fig. 5. Example of the CRB part of a chromosome.

Fig. 3. Example of decision tree generated by the C4.5 algorithm applied to the transformed training set.
consequent ("THEN" part). Since each branch is identified by one of the intervals determined by the discretization process and an input variable is involved in just one node in a path, the rules extracted from the decision tree are expressed as in (2). Each rule is identified by an integer from 1 to MC 45 , where MC 45 is the number of rules extracted from the tree and included in the initial rule base.
Fig. 3 shows an example of a decision tree generated by the C4.5 algorithm from a training set characterized by six input variables and two classes (C1 , C2 ). Each input variable Xf , f = 1, . . . , 6, has been partitioned with Tf = 5 fuzzy sets. We observe that only three out of the six original input variables are included in the decision tree. This is due to the well-known characteristic of the C4.5 algorithm that can select features during the generation of the tree. Fig. 4 shows the rule base extracted from the decision tree of Fig. 3. We note that the rule base consists of 13 rules, which correspond to the 13 possible paths from the root to the leaf nodes.
B. Rule and Condition Selection
The CRB part of the chromosome is a vector of Mmax pairs pm = (km , vm ), where km identifies the index of the rule in

the set of MC 45 rules extracted from the decision tree, and vm = [vm,1 , . . . , vm,F ] is a binary vector, which indicates, for each condition in the rule, if the condition is present (vm,f = 1) or corresponds to a "don't care" (vm,f = 0). Rule bases generated by the C4.5 algorithm could include a high number of rules,
especially when dealing with large and high-dimensional train-
ing sets. With the aim of obtaining compact and interpretable
FRBCs, we have set an upper bound Mmax to the number of rules that can be contained in any rule base generated dur-
ing the evolutionary process. In the experiments, we have set
Mmax = 50. In our previous works [26], we have verified that this value permits us to generate FRBCs with reasonable ac-
curacy, maintaining the complexity at an adequate level. Let
MC 45 be the number of rules extracted from the decision tree. If MC 45 < Mmax , then Mmax = MC 45 . During the evolutionary process, the MOEA can generate rule bases, which contain
a number of rules lower than Mmax . Indeed, if km = 0, then the mth rule is not included in the rule base. Further, the number of conditions can be lower than the number F of features. Indeed,
if vm,f = 0, then the f th condition of the mth rule is replaced by a "don't care" condition and, therefore, is not considered in
the inference process. Whenever a condition selection is per-
formed on the rule, the rule weight associated with the rule is
recomputed.
As an example, given a two input fuzzy model, let us assume
that the C4.5 algorithm has generated the following four rules: R1 : IF X1 is A~1,1 and X2 is A~2,1 THEN Y is C1 R2 : IF X1 is A~1,2 and X2 is A~2,2 THEN Y is C2 R3 : IF X1 is A~1,5 and X2 is A~2,3 THEN Y is C1 R4 : IF X2 is A~2,1 THEN Y is C1 .
Let us suppose that, during the evolutionary process executed
with Mmax = 3, the CRB chromosome part shown in Fig. 5 is generated.
The first gene of the chromosome selects rule R2 (k1 is equal to 2) with all the conditions (both v1,1 and v1,2 are equal to 1).

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

255

Fig. 6. CD B part of a chromosome.

The second gene selects rule R3 (k2 is equal to 3) with only the first condition (v2,1 is equal to 1, while v2,2 is equal to 0). The third gene selects no rule (k3 is equal to 0).
The rule base corresponding to the chromosome in Fig. 5

will, therefore, be

R2 : IF X1 is A~1,2 and X2 is A~2,2 THEN Y is C2 R3 : IF X1 is A~1,5 THEN Y is C1 .

We note that, even though Mmax = 3, only two rules have been selected in the final rule base. Furthermore, for the third

rule, only the first condition has been selected.

The CDB part of the chromosome codifies the upper membership functions of each variable Xf . Since the lower membership functions are built, as described in Section II, from

the upper membership functions, the CDB part codifies exclusively these functions. Since we adopt strong fuzzy parti-

tions for defining the upper membership functions with, for j = 2, . . . , Tf - 1, Żbf,j = cŻf,j-1 and Żbf,j = aŻf,j+1 , each triangular fuzzy set (aŻf,j , Żbf,j , cŻf,j ) of the partition is completely defined by fixing the positions of the cores Żbf,j along the universe Uf of the f th variable (we normalize each variable in [0,1]). Since Żbf,1 and Żbf,Tf coincide with the lower and upper extremes of universe Uf , the partition of each linguistic variable Xf is completely defined by Tf - 2 parameters {Żbf,2 , . . . , Żbf,Tf -1 },
which define the positions of the cores of the upper member-

ship functions defined on Xf . As shown in Fig. 6, the CDB chromosome part, therefore, consists of F vectors of Tf - 2 real numbers. A good level of integrity, in terms of order, cov-

erage, and distinguishability, of the partitions is ensured by,

j  [2, Tf - 1], forcing Żbf,j to vary in the definition interval

[Żbf , j

-

Żbf , j -Żbf , j -1 2

, Żbf,j

+

Żbf , j + 1 -Żbf , j 2

].

C. Genetic Operators

Both crossover and mutation operators are employed to gen-
erate the offspring population. In particular, we apply the one-
point crossover to the CRB part and the BLX- crossover, with  = 0.5, to the CDB part. In applying the one-point crossover, the common gene between the two mating chromosomes s1 and s2 is determined by extracting randomly a number in [1, MAX ], where MAX is the maximum number of rules in s1 and s2 . The crossover point is always chosen between two rules and not
within a rule.
As regards mutation, two operators are applied to the CRB part. Both the operators randomly choose a pair pm , i.e., a rule, in the chromosome. Then, the first operator replaces the rule in
pm with another rule by setting km to an integer value randomly generated in [1, MC 45 ].
The second operator modifies the rule in pm by complementing each gene vm,f with a probability equal to Pcond (Pcond = 2/f in the experiments).

Fig. 7. Application scheme of the genetic operators.
The mutation operator applied to CDB , first, randomly chooses an input variable Xf , f  [1, F ], and a fuzzy set j  [2, Tf - 1] and then replaces the value of Żbf,j with a value randomly chosen within the definition interval of Żbf,j .
If, after applying the crossover, the rule base contains one or more pairs of equal rules, we simply eliminate one of the rules from each pair setting the corresponding km to zero.
D. Multiobjective Evolutionary Algorithm
The MOEA used in this paper is the (2 + 2)M-PAES algorithm proposed in [41] and adopted in [26]. The application scheme of the crossover and mutation operators employed in (2 + 2)M-PAES for generating the offspring solutions o1 and o2 from the current solutions s1 and s2 is shown in Fig. 7. Here, PCRB , PCDB , PMRB 1 , and PMRB 2 represent the probabilities of applying the crossover operators to CRB and CDB parts and the first and the second mutation operators to CRB , respectively. PMDB represents the probability of applying the mutation operator to CDB . Unlike classical (2 + 2)PAES, which maintains the current solutions s1 and s2 until they are not replaced by solutions with particular characteristics, we observe that in (2 + 2)M-PAES s1 and s2 are randomly extracted at each iteration.
At the beginning, we generate two current solutions s1 and s2 . While the genes of the CDB part and the km values of the CRB part of s1 and s2 are randomly generated, all the values vm,f of the conditions of all the rules are set to 1. An offspring solution ox is added to the archive only if it is dominated by no solution contained in the archive; possible solutions in the archive dominated by ox are removed. If the archive is full and no solution in the archive can be removed, then the offspring solution ox is inserted into the archive and the solutions (possibly ox itself), which belong to the region with the highest crowding degree, are removed. If the region contains more than one solution, then, the solution to be removed is randomly chosen.

256

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

TABLE I FINANCIAL DATASETS USED IN THE EXPERIMENTS
(SORTED FOR INCREASING IRS)

Dataset
BLA CARD AF ARB COMM SL LEN DPKG BAN GIV COI

#Instances
1747 176 463
1894 1641 16 102 35 798 24 772 72 983 45 211 150 000 9823

#Attributes
42 66 121 7 83 63 20 23 13 10 85

IR
1.47 1.59 2.50 3.09 3.34 4.16 4.50 7.20 7.54 13.96 15.79

(2 + 2)M-PAES concurrently optimizes three objectives, namely FPR, TPR and complexity. The complexity is measured as the sum of the conditions, which compose the antecedents of the rules in the rule base. This number is denoted as TRL. Low values of TRL correspond to rule bases characterized by a low number of rules and a low number of input variables really used in each rule.
IV. EXPERIMENTS AND RESULTS
We analyzed 11 financial datasets. For each dataset, we performed a tenfold cross-validation and executed three trials for each fold with different seeds for the random function generator (30 trials in total). We fixed 50 000 evaluations as stopping criteria.
In the following, we first describe the financial datasets. Then, we show the results obtained by IT2-PAES-RCS, PAES-RCS, PAES-RCS-SD, FARC-HD, FURIA, C4.5, and its cost-sensitive version C4.5-CS. Finally, we analyze the results along accuracy and interpretability dimensions.
A. Financial Datasets
In financial applications, as in many real-world problems, the data are highly unbalanced. For example, in a credit card application, the number of good customers is much higher than that of bad customers; in fraud detection, the majority of the data are normal transactions whereas a few fraudulent transactions are usually present. Most classifiers designed for minimizing the global error rate perform poorly on unbalanced datasets because they misclassify most of the data belonging to the class represented by few examples. Hence, in our experiments, in order to evaluate the proposed system for various financial applications, we have chosen 11 datasets with various sizes and different levels of imbalance ratios (IRs) between the minority and majority classes. The chosen datasets cover different financial applications, including credit card and loan authorization, stock market related predictions, insurance, fraud detection, and investment banking.
We have used 11 real-world datasets from various financial domains. Table I summarizes the main characteristics of these datasets. For each dataset, we report the name, the number of

instances (#Instances), the number of attributes (#Attributes), and the IR. We recall that IR is defined as the ratio between the number of instances of the majority class and of the minority class. The datasets are sorted for increasing IRs. We do not show the number of classes because all the datasets represent two class problems.
In the following, we shortly describe each financial dataset.
1) BLA: The dataset is related to the prediction of good (profitable) or bad (nonprofitable) customers for bank loan authorization.
2) CARD: The dataset is used to evaluate if a customer is going to default on a credit card or no.
3) AF: The dataset is related to investment banking and is used to predict if customers are going to pay back their loans or if they will default on the given loan.
4) ARB: The dataset is used for spotting arbitrage opportunities in the London International Financial Futures Exchange (LIFFE) market. The dataset was developed in [4]­[6] to identify arbitrage situations by analyzing option and futures prices in the LIFFE market.
5) COMM: The dataset is used for the evaluation of customers (Fraud or No Fraud customer) for commercial loans applications.
6) SL: The dataset is used for the evaluation of customers (good or bad customers) for personal small loans applications where there is no knowledge on the customer full credit history.
7) LEN: The dataset is used for evaluation of small companies (good or bad customer) for business loans applications when the customer full credit history is known.
8) DPKG: The dataset is used to predict whether in an auction, the customer will be real or fraud.
9) BAN: The dataset is used to predict if a customer is eligible for increasing the credit limits on her/his credit cards.
10) GIV: The dataset is used to predict whether an applicant is eligible to give her/him extra credit on her/his existing loan or not.
11) COI: The dataset is used to predict whether a customer will buy a caravan insurance or not.
B. Classifiers
In this section, we shortly describe the classifiers applied to the financial datasets. IT2-PAES-RCS was widely discussed in Section III. The PAES-RCS algorithm used in this paper is slightly different from the original version. Indeed, to manage unbalanced datasets, we use three objectives as in IT2-PAESRCS, but generate type-1 FRBCs. PAES-RCS-SD is the version of PAES-RCS with three objectives and with the scaled domain approach.
FARC-HD was introduced in [28] and is a single-objective evolutionary fuzzy classifier, which exploits association rules mining for generating FRBCs. FARC-HD is based on three stages. First, it mines all possible fuzzy association rules building a search tree to list all frequent fuzzy item sets, limiting the depth of the branches in order to find a small number of short fuzzy rules. Second, it uses a pattern weighting scheme

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

257

to reduce the number of candidate rules, preselecting the most interesting rules, in order to decrease the computational costs for the third step. Finally, a single-objective genetic algorithm, namely CHC, is used to select and tune a compact set of fuzzy association rules. FRBCs generated by FARC-HD use the certainty factor and the additive combination [59] as rule weight and reasoning method, respectively.
FURIA is an extension of the RIPPER algorithm [60]. Given a classification problem with K classes, prior to the learning process, RIPPER sorts the training data by class label in ascending order according to the corresponding class frequencies. Then, rules are learned for the first K - 1 classes, starting with the least frequent. Once a rule has been generated, the instances covered by that rule are removed from the training data, and this is repeated until no instance from the target class is left. The algorithm then proceeds with the next class. Finally, when RIPPER finds no more rules to learn, a default rule (with empty antecedent) is added for the last (and hence most frequent) class. To learn each rule, the training set is split into a growing set and a pruning set: the former is used to specialize the rule by adding antecedents, while the latter is used to generalize the rule by removing antecedents. FURIA extends RIPPER along three directions: 1) the use of fuzzy rather than crisp rules, employing fuzzy intervals with trapezoidal membership functions instead of crisp intervals; 2) the exploitation of unordered rather than ordered rule sets; and 3) the introduction of a novel rule stretching method in order to manage uncovered examples.
C4.5 builds decision trees from a set of training data using the concept of information entropy. At each node of the tree, the C4.5 algorithm chooses one attribute of the training set that most effectively splits its set of samples into subsets enriched in one class or the other. The splitting criterion is the normalized information gain that results from choosing an attribute for splitting the data. The attribute with the highest normalized information gain is chosen to make the decision. The cost-sensitive version of C4.5, denoted as C4.5-CS, exploits an instance weighting method similar to the one adopted in the boosting decision tree approach developed by Quinlan [61]. C4.5-CS changes the class distribution so that the induced tree is in favor of the class with high weight/cost. Thus, this version of the C4.5 is less likely to commit errors with high costs.
Before applying FARC-HD, FURIA, and C4.5, the datasets are preprocessed by using the synthetic minority oversampling technique (SMOTE) [62]. In SMOTE, the minority class is oversampled by taking each minority class sample and introducing synthetic examples along the line segments joining any or all of the k minority class nearest neighbors. Depending upon the amount of oversampling required, neighbors from the k-nearest neighbors are randomly chosen.
Table II shows the parameters used for IT2-PAES-RCS, PAES-RCS, and PAES-RCS-SD. The values of the parameters come, on the one side, from the long experience we maturated in the application of (2 + 2)M-PAES for generating fuzzy rule-based systems since our initial paper on this subject [41]. On the other side, we performed a number of experiments with different values of these parameters using the datasets in Table I and realized that the parameters in Table II are effective

TABLE II VALUES OF THE PARAMETERS USED IN THE EXPERIMENTS FOR
IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD

AS

(2 + 2)M-PAES archive size

128

Tf

Number of fuzzy sets for each variable X f , f = 1, . . . , F

5

Mm ax

Maximum number of rules in a rule base

50

PCRB

Probability of applying the crossover operator to C RB

0.4

PCDB

Probability of applying the crossover operator to C D B

0.5

PM RB 1 Probability of applying the first mutation operator to C RB

0.1

PM RB 2 Probability of applying the second mutation operator to C RB 0.6

PM D B Probability of applying the mutation operator to C D B

0.2

also for these datasets. For the other algorithms, we adopted the implementation in Keel [63] and the default parameters.

C. Analysis of the Results

The execution of IT2-PAES-RCS, PAES-RCS, and PAES-

RCS-SD generates a set of solutions with different tradeoffs

among the three objectives. At the end of each execution of the

algorithms, we verified that the archive of (2 + 2)M-PAES is

always full for each dataset in Table I. Thus, each execution of

the three algorithms generates 128 different FRBCs. In order to

analyze the results of IT2-PAES-RCS, PAES-RCS, and PAES-

RCS-SD, each 3-D Pareto front approximation is projected onto

the FPR-TPR plane: Each FRBC of the Pareto front approxima-

tion is, therefore, represented as a point corresponding to the pair

(FPR, TPR). We recall that one classifier in the FPR-TPR plane

is better than (dominates) another if it is located more north-west

(higher TPR and/or lower FPR) than the other [64]. For this rea-

son, in order to select a set of potentially optimal FRBCs, we

extract the nondominated solutions obtained on the training set

in the FPR-TPR plane. Since we do not assume to use any cost

function for selecting a single optimal classifier, we consider

all the non-dominated solutions in the FPR-TPR plane. With

the aim of comparing the outputs of the three multiobjective

evolutionary approaches among them and with the other algo-

rithms, for each nondominated solution, we calculate the area

under

the

curve

(AUC),

defined

as

AU C

=

100 +

TPR 2

-FPR ,

and select the solution with the highest AUC on the training

set. The highest AUC identifies the most North­West solution

in the FPR-TPR plane. Thus, for each comparison algorithm,

we consider just one classifier and compare these classifiers in

terms of AUC computed on the test set.

Table III shows, for each dataset, the average AUC, FPR, and

TPR on both the training and the test sets, the average number

of rules, and the average TRL for the classifiers with the highest

AUC on the training set generated by IT2-PAES-RCS, PAES-

RCS, and PAES-RCS-SD, and for the classifiers generated by

FARC-HD, FURIA, C4.5, and C4.5-CS. For each dataset, we

have shown in bold the best values. We can observe that C4.5

and C4.5-CS suffer very much from overtraining. Indeed, the

value of the AUC is very high on the training set, but is quite low

on the test set. Although it is less evident than for C4.5 and C4.5-

CS, also FURIA suffers from overtraining: the AUC computed

on the test set is at least for some datasets much lower than on the

training set. IT2-PAES-RCS, PAES-RCS, and PAES-RCS-SD

do not suffer from overtraining and show similar performance,

thus testifying the validity of the three objective approach.

258

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

TABLE III AVERAGE AUC, FPR, AND TPR ON BOTH THE TRAINING AND THE TEST SETS, AVERAGE TRL, AND NUMBER OF RULES FOR THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, PAES-RCS-SD, AND FOR THE CLASSIFIERS GENERATED BY FARC-HD, FURIA, C4.5,
AND C4.5-CS

BLA CARD AF ARB COMM SL LEN DPKG BAN

IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS

AUCT r
65.36 68.97 69.11 68.37 64.39 90.43 88.71
68.57 68.45 68.57 68.41 70.96 94.43 92.90
62.27 66.56 67.34 68.53 66.59 88.14 87.37
94.73 97.21 95.23 86.15 98.23 98.64 98.73
67.19 67.42 67.33 76.77 80.47 93.91 93.36
60.03 60.35 61.20 65.24 69.20 93.72 94.94
63.92 64.14 64.42 70.59 83.86 92.79 94.91
67.48 67.89 67.88 70.66 81.67 96.50 97.83
80.85 80.26 81.02 85.41 92.96 95.34 98.73

FPRT r
44.95 41.10 41.11 36.04 35.76 10.40 14.38
25.74 26.90 26.80 24.65 25.29 4.69 9.41
28.44 36.98 30.24 26.18 35.90 10.16 21.72
6.88 3.01 6.12 15.49 2.28 2.16 2.42
18.76 17.59 17.38 10.03 9.33 4.36 13.09
34.50 38.23 40.04 33.08 36.42 4.53 9.81
36.11 35.95 36.61 23.77 5.04 3.46 10.15
22.53 23.46 23.72 27.48 14.11 1.88 4.28
16.85 22.44 16.73 13.82 9.12 5.77 2.42

TPRT r
75.68 79.03 79.33 72.78 64.53 91.26 91.81
62.87 63.79 63.95 61.59 67.20 93.56 95.20
52.98 70.09 64.92 63.24 69.07 86.43 96.46
96.33 97.43 96.52 87.80 98.73 99.44 99.88
53.13 52.44 52.04 63.57 70.27 92.18 99.82
54.56 58.93 62.43 63.56 74.82 91.97 99.69
63.95 64.24 65.46 64.96 72.76 89.03 99.97
57.50 59.24 59.48 68.79 77.44 94.88 99.94
78.56 82.96 78.77 84.64 95.04 96.46 99.88

AUCT s
59.35 59.97 58.70 59.90 58.37 57.89 56.24
68.51 68.34 68.51 66.66 68.00 65.78 66.26
54.41 52.72 54.79 55.22 53.90 54.06 50.95
94.25 97.02 94.69 87.28 98.14 98.18 98.37
66.44 66.05 66.33 65.86 65.14 61.04 61.62
59.64 59.58 59.99 58.80 58.13 54.15 54.83
63.10 62.96 63.29 59.34 52.98 55.09 56.35
67.17 67.50 67.53 64.97 63.58 75.23 78.03
80.59 79.76 80.76 77.24 77.61 70.24 98.37

FPRT s
50.13 48.78 50.22 42.27 40.16 38.04 39.77
25.74 27.00 26.87 24.60 25.36 28.98 30.25
32.77 45.06 36.50 32.29 39.28 32.32 43.29
7.04 3.17 6.49 15.91 3.23 3.39 2.50
19.08 18.17 17.79 10.18 9.76 22.18 28.66
34.61 38.20 40.51 33.22 37.22 22.36 26.36
36.39 36.42 37.07 24.08 5.55 18.46 25.57
22.58 23.62 23.74 27.54 14.55 8.10 9.80
17.24 23.40 17.20 30.07 39.09 53.11 2.50

TPRT s
68.82 68.73 67.62 62.07 56.89 53.82 52.26
62.77 63.69 63.89 58.04 61.35 60.53 62.77
41.59 50.50 46.08 42.73 47.08 40.45 45.20
95.55 97.21 95.88 90.48 99.50 99.75 99.25
51.96 50.26 50.44 41.91 40.05 44.26 51.90
53.90 57.37 60.48 50.82 53.48 30.67 36.01
62.58 62.33 63.64 42.75 11.51 28.64 38.28
56.91 58.62 58.80 57.48 41.71 58.56 65.87
78.44 82.93 78.74 84.55 94.31 93.59 99.25

TRL
123.7 159.6 192.6 598.8 18.4 445.6 348.8
458.1 485.5 485.6 1852.6 22.4 33396.8 26145.2
364.7 501.1 592.5 768.7 31.8 508.3 412.4
51.4 49.0 47.9 35.5 60.0 78.4 32.4
115.4 145.1 167.6 313.3 73.6 2470.0 2139.6
249.4 306.1 423.4 2154.6 70.2 7962.8 7836.8
191.8 236.6 300.4 1855.9 202.4 3987.2 3776.4
94.2 102.4 138.2 1959.7 560.8 9379.2 7111.2
111.5 98.6 114.0 810.9 233.4 1932.8 273.5

#Rules
28.8 34.0 37.1 203.0 7.6 223.8 175.4
27.4 28.8 27.7 628.0 5.6 16699.4 13073.6
33.0 38.8 41.3 264.0 11.6 255.4 207.2
21.1 20.3 20.0 16.6 26.0 40.2 17.2
27.5 30.9 35.4 118.8 20.8 1236.0 1070.8
21.9 24.1 32.2 720.6 19.2 3982.4 3301.8
42.8 50.6 59.2 644.4 49.2 1994.6 1889.2
23.4 24.4 29.5 664.3 100.4 4690.6 3556.6
28.3 24.6 30.2 331.2 41.8 966.6 17.2

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

259

TABLE III (Continued)

AUCT r FPRT r TPRT r AUCT s FPRT s TPRT s

TRL

#Rules

GIV IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS
COI IT2-PAES-RCS PAES-RCS PAES-RCS-SD FARC-HD FURIA C4.5 C4.5-CS

72.59 68.14 72.77 73.44 78.35 86.38 95.99
66.36 67.88 66.87 65.51 95.50 97.60 95.83

17.68 13.64 17.47 13.07 14.46 10.03 8.03
34.84 31.45 32.94 32.40 7.10 3.68 3.50

62.87 49.92 63.01 59.96 71.15 82.79 100.00
67.57 67.21 66.69 66.20 98.10 98.89 91.65

72.54 68.07 72.67 66.51 73.26 70.53 71.51
63.93 62.62 63.74 61.74 62.13 61.34 60.43

17.69 13.63 17.44 13.05 14.53 13.40 11.82
39.94 41.36 39.25 38.90 73.29 73.48 66.91

62.77 49.77 62.78 46.07 61.04 54.46 54.84
67.80 66.68 66.74 65.45 97.54 96.17 87.78

40.3 27.8 43.1 253.2 129.6 7045.6 9162.4
55.87 92.63 85.5 1304.1 510.5 596.4 772.4

19.8 14.9 19.9 87.6 19.8 3523.8 4582.2
22.1 29.9 27.3 457.6 91.4 299.2 387.2

TABLE IV RESULTS OF THE NONPARAMETRIC STATISTICAL TESTS ON THE AUC COMPUTED ON THE TEST SET AMONG THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD, AND THE CLASSIFIERS GENERATED BY FARC-HD,
FURIA, C4.5, AND C4.5-CS
To statistically verify these observations, we apply nonparametric statistical tests for multiple comparisons. First, for each approach, we generate a distribution consisting of the average values of the AUCs on the test set. Then, we apply the Friedman test in order to compute a ranking among the distributions [65], and the Iman and Davenport test [66] to evaluate whether there exist statistically relevant differences among the distributions. If there exists a statistical difference, we apply a posthoc procedure, namely the Holm test [67]. This test allows detecting effective statistical differences between the control approach, i.e., the one with the lowest Friedman rank, and the remaining approaches.
Table IV shows the results of the nonparametric statistical tests: for each algorithm, we show the Friedman rank and the Iman and Davenport p-value. If the p-value is lower than the

level of significance  (in the experiments,  = 0.05), we can reject the null hypothesis and affirm that there exist statistical differences between the multiple distributions associated with each approach. Otherwise, no statistical difference exists among the distributions and therefore the solutions are statistically equivalent. We observe that the Iman and Davenport statistical hypothesis of equivalence is rejected, and therefore, statistical differences among the six approaches are detected. Thus, we have to apply the Holm posthoc procedure considering the PAES-RCS-SD as control algorithm (associated with the lowest rank and in bold in the table). In the part of the table corresponding to the results obtained by the application of the Holm posthoc procedure, the algorithms are sorted by decreasing Friedman ranks. Index i denotes the position of the algorithm in the sorted list (i = 1 and i = 6 correspond to the lowest and highest Friedman ranks, respectively). The Holm posthoc procedure computes the z-values and p-values shown in the table: if the p-value of the algorithm in position i is lower than the adjusted  value (/i), then the null hypothesis is rejected.
The Holm posthoc procedure states that the AUCs on the test set of IT2-PAES-RCS and PAES-RCS are statistically equivalent to the AUC of PAES-RCS-SD. The null hypothesis is rejected for all the other algorithms. Thus, we can conclude that the three versions of PAES-RCS with three objectives obtain classifiers, which outperform the ones obtained by the other approaches in terms of AUCs. In addition, this result is obtained without rebalancing the datasets. Further, if we analyze the Friedman ranks, we realize that the two algorithms with the highest ranks are just PAES-RCS-SD and IT2-PAES-RCS. Further, both PAES-RCS-SD and IT2-PAES-RCS obtain this result with classifiers characterized by a low number of rules. To verify this observation, we have also applied the non-parametric statistical tests for multiple comparisons to the number of rules and to the TRL values.
Tables V and VI show the results. Since the null hypothesis is rejected for both the tests, we apply the Holm posthoc procedure by using IT2-PAES-RCS as control algorithm. The procedure states that, in terms of average number of rules

260

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

TABLE V RESULTS OF THE NONPARAMETRIC STATISTICAL TESTS ON THE NUMBER OF RULES AMONG THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD, AND THE CLASSIFIERS GENERATED BY FARC-HD, FURIA, C4.5, AND C4.5-CS

TABLE VII MEANING OF THE ATTRIBUTES OF THE ARB DATASET

Name MoneyNess Basis % (x10 000) Und (x10) Interest Ask % Futures (T-t) C-P % (x100) Profit after TC (x 1 000 000)

Description
Strike Price/Underlying Index Level Futures price minus spot index level, divided by futures price, multiplied by 10,000 Spot index level divided by futures price, multiplied by 10 The LIBOR ask rate for the maturity closest to the maturity of futures contract, multiplied by 100 The nave trigger, profit after transaction costs, divided by futures price, multiplied by 1 000 000 The difference between the call and the put prices, divided by futures price The nave trigger, profit after transaction costs, divided by futures price, multiplied by 1 000 000

TABLE VI RESULTS OF THE NONPARAMETRIC STATISTICAL TESTS ON THE TRL AMONG THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, AND PAES-RCS-SD, AND THE CLASSIFIERS
GENERATED BY FARC-HD, FURIA, C4.5, AND C4.5-CS
(see Table V), the classifiers generated by PAES-RCS, PAESRCS-SD, and FURIA are statistically equivalent to the ones generated by IT2-PAES-RCS. On the contrary, the null hypothesis is rejected for FARC-HD, C4.5, and C4.5-CS. As regards TRL, the Holm posthoc procedure concludes that the most accurate classifiers generated by IT2-PAES-RCS result to be characterized by an average TRL value statistically equivalent to the most accurate classifiers generated by PAES-RCS and to the classifiers generated by FURIA. On the contrary, the null hypothesis is rejected for PAES-RCS-SD, FARC-HD, C4.5, and C4.5-CS.
Among the classifiers used for comparison, only FURIA shows a complexity comparable with the three versions of

PAES-RCS. We have to highlight, however, that the interpretability of the classifiers generated by FURIA is limited by the membership functions computed by the method. Indeed, these membership functions are hardly describable using linguistic terms. On the contrary, thanks to the constraints imposed on the membership function learning during the evolutionary process, the partitions generated by IT2-PAES-RCS, PAES-RCS, and PAES-RCS-SD can be easily described by linguistic terms. Just to provide a glimpse of this interpretability, we consider one of the datasets in Table I, namely ARB. Table VII describes in detail the meaning of the attributes for the ARB dataset. We recall that the output here is spotting arbitrage opportunities in the LIFFE market.
Fig. 8 shows an example of partitions generated by IT2PAES-RCS for one of the classifiers with the highest AUC on the training set for the ARB. Here, only six out of seven attributes are shown since one of the attributes was not used in the final rule base. We can observe that, although the evolutionary process has tuned the IT2 fuzzy sets on the specific dataset, the partitions of the different attributes result to be easily interpretable.
As regards the interpretability of the rules, Fig. 9 shows the rule base of the classifier whose data base is shown in Fig. 8. Here, we do not show the "don't care" conditions, since they do not contribute to the inference process and penalize the interpretability of the rule base. The expert can deduce interesting knowledge from the rules of the classifier. Indeed, he/she can, for instance, discover that intermediate values of C-P (C-P is M) lead to conclude that the class is Arbitrage Opportunity. On the other hand, very high values of Futures (Futures is VH) allow inferring that the class is non-Arbitrage Opportunity.
The nonparametric statistical tests for multiple comparisons have shown that the classifiers generated by IT2-PAES-RCS, PAES-RCS, and PAES-RCS-SD achieve similar AUC on the test set and have similar complexity, at least in terms of number of rules. We observe, however, that IT2-PAES-RCS is characterized by the minimum Friedman rank in both Tables V and VI. Thus, we decided to perform a statistical analysis between IT2PAES-RCS and each of the other two approaches separately. We applied the Wilcoxon signed-rank test for pairwise comparison [68], considering IT2-PAES-RCS as control algorithm,

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

261

Fig. 8. Example of partitions generated by IT2-PAES-RCS for one of the classifiers with the highest AUC on the training set for the dataset ARB.

Fig. 9. Rule base of the classifier whose data base is shown in Fig. 8.

TABLE VIII RESULTS OF THE WILCOXON SIGNED-RANK TEST ON AUC, TRL, AND NUMBER OF RULES AMONG THE CLASSIFIERS WITH THE HIGHEST AUC ON THE TRAINING SET GENERATED BY IT2-PAES-RCS, PAES-RCS, AND
PAES-RCS-SD

AU CT s
IT2-PAES-RCS versus PAES-RCS IT2-PAES-RCS versus PAES-RCS-SD
TRL
IT2-PAES-RCS versus PAES-RCS IT2-PAES-RCS versus PAES-RCS-SD
#Rules
IT2-PAES-RCS versus PAES-RCS IT2-PAES-RCS versus PAES-RCS-SD

R+

R-

p-value Hypothesis (alpha = 0.05)

46.0 20.0 0.230

Not Rejected

15.5 39.5

1

Not Rejected

R+

R-

p-value Hypothesis(alpha = 0.05)

58.0 8.0

0.023

Rejected

63.0 3.0

0.006

Rejected

R+

R-

p-value Hypothesis(alpha = 0.05)

58.0 8.0

0.023

Rejected

63.0 3.0

0.006

Rejected

to the distributions of AUCs calculated on the test set, average number of rules, and average TRL.
Table VIII shows the results of the test. The null hypothesis is not rejected for the AUC computed on the test set, but is rejected for the average number of rules and average TRL. We can conclude that IT2-PAES-RCS generated classifiers that achieve the same accuracy in terms of AUC as PAES-RCS and PAES-RCS-SD, but with a lower number of rules and a lower TRL. Thus, the classifiers generated by IT2-PAES-RCS result to be less complex and, therefore, more interpretable.
V. CONCLUSION
Financial data are often strongly unbalanced and characterized by a high level of uncertainty. In this paper, we have proposed to deal with financial data classification by adopting rule-based classifiers generated by an MOEA. These classifiers have proved to be very effective in terms of accuracy. Further,

262

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

they are generally characterized by a low number of rules and TRL, and a good integrity of the partitions, thus making them very interpretable. Interpretability is considered essential in the financial context, since the comprehension of how inputs and output are related to each other is crucial to take both operative and strategic decisions.
We have extended PAES-RCS, an MOEA-based approach to learn concurrently the rule and data bases of FRBCs. In order to cope with unbalanced datasets, we have split the accuracy into two objectives, namely TPR and FPR, and we have used an approach denoted as scaled dominance to give minority classes a fair chance when competing with a majority class. Further, we have coped with uncertainty by adopting IT2 fuzzy sets rather than type-1 fuzzy sets. This has required using a different inference mechanism. We have tested the three improvements on 11 financial datasets and compared the results with the ones obtained by the FRBCs FARC-HD and FURIA, the classical C4.5 decision tree algorithm and its cost-sensitive version. Using nonparametric statistical tests, we have shown that the three improvements allow generating classifiers, which outperform the comparison approaches both in terms of accuracy, computed as AUC, and complexity, computed as number of rules. Finally, the extension of PAES-RCS, which integrates the three improvements, has proved to achieve high accuracy with, on average, the lowest number of rules and TRL.
REFERENCES
[1] "The Regulatory Opportunity in Financial Services," (2014). [Online]. Available: http://butleranalytics.com/regulatory-opportunityfinancial-services/
[2] "Predictive Models - Risks and Benefits," (2014). [Online]. Available: http://butleranalytics.com/predictive-models-risks-benefits/
[3] "Predictive Model Management Strategy," (2014). [Online]. Available: http://butleranalytics.com/financial-regulation-predictive-models/
[4] A. Garcia-Almanza and E. Tsang, "Forecasting stock prices using genetic programming and chance discovery," presented at the 12th Int. Conf. Comput. Econ. Finance, Limassol, Cyprus, Jun. 22­24, 2006.
[5] A. Garcia-Almanza and E. Tsang, "Evolving decision rules to predict investment opportunities," Int. J. Autom. Comput., vol. 5, no. 1, pp. 22­ 31, 2008.
[6] A. Garcia-Almanza, "New classification methods for gathering patterns in the context of genetic programming," Ph.D. dissertation, Dept. Comput. Electron. Syst., Univ. Essex, Colchester, U.K., 2008.
[7] L. Breiman, "Random Forests," Mach. Learn., vol. 45, no. 1, pp. 5­32, 2001.
[8] J. Casillas, O. Cordon, F. Herrera, L. Magdalena, Eds., Interpretability Issues in Fuzzy Modelling. New York, NY, USA: Springer, 2003.
[9] M. Setnes and H. Roubos, "GA-fuzzy modelling and classification: Complexity and performance," IEEE Trans. Fuzzy Syst., vol. 8, no. 5, pp. 509­ 522, Oct. 2000.
[10] H. Ishibuchi and T. Yamamoto, "Interpretability issues in fuzzy geneticbased machine learning for linguistic modelling," in Modelling with Words (Lecture Notes in Computer Science), vol. 2873. Berlin, Germany: Springer-Verlag, 2003, pp. 209­228.
[11] H. Ishibuchi, T. Nakashima, and M. Nii, Classification and Modeling with Linguistic Information Granules: Advanced Approaches to Linguistic Data Mining. Berlin, Germany: Springer-Verlag, 2004.
[12] P. Ducange and F. Marcelloni, "Multi-objective evolutionary fuzzy systems," in Proc. 9th Int. Workshop Fuzzy Logic Appl., 2011, pp. 83­90.
[13] M. Fazzolari, R. Alcala´, Y. Nojima, H. Ishibuchi, and F. Herrera, "A review of the application of multiobjective evolutionary fuzzy systems: Current status and further directions," IEEE Trans. Fuzzy Syst., vol. 21, no. 1, pp. 45­65, Feb. 2013.
[14] P. Melin and O. Castillo, "A review on type-2 fuzzy logic applications in clustering, classification and pattern recognition," Appl. Soft Comput., vol. 21, pp. 568­577, 2014.

[15] C. Glackin, L. Maguire, R. McIvor, P. Humphreys, and P. Herman, "A comparison of fuzzy strategies for corporate acquisition analysis," Fuzzy Sets Syst., vol. 159, no. 18, pp. 2039­2056, 2007.
[16] D. Bernardo, H. Hagras, and E. Tsang, "A genetic type-2 fuzzy logic based system for the generation of summarised linguistic predictive models for financial applications," Soft Comput., vol. 17, no. 12, pp. 2185­2201, 2013.
[17] J.A Sanz, D. Bernardo, F. Herrera, H. Bustince, and H. Hagras, "A compact evolutionary interval-valued fuzzy rule-based classification system for the modeling and prediction of real-world financial applications with imbalanced data," IEEE Trans. Fuzzy Syst., vol. 23, no. 4, pp. 973­990, Aug. 2015.
[18] D. Wu and W. Tan, "Genetic learning and performance evaluation of interval type-2 fuzzy logic controllers," Eng. Appl. Artif. Intell., vol. 19, no. 8, pp. 819­841, 2006.
[19] R. Mart´inez-Soto, O. Castillo, L. T. Aguilar, and A. R. D´iaz, "A hybrid optimization method with PSO and GA to automatically design type-1 and type-2 fuzzy logic controllers," Int. J. Mach. Learn. Cybern., vol. 6, no. 2, pp. 175­196, 2015.
[20] O. Linda and M. Manic, "Uncertainity-robust design of interval type-2 fuzzy logic controller for delta parallel robot," IEEE Trans. Ind. Informat., vol. 7, no. 4, pp. 661­670, Nov. 2011.
[21] M. Almaraahi, R. John, and S. Ahmadi, "Learning of type-2 fuzzy logic systems by simulated annealing with adaptive step size," in Electrical Engineering and Intelligent Systems (ser. Lecture Notes in Electrical Engineering), vol. 130. Berlin, Germany: Springer-Verlag, 2013, pp. 53­64.
[22] T. Kumbasar and H. Hagras, "Big bang-big crunch optimization based Interval type-2 fuzzy PID cascade controller design strategy," Inf. Sci., vol. 282, pp. 277­295, 2014.
[23] J. Mendel, H. Hagras, W-W. Tan, W. Melek, and H. Ying, Introduction to Type-2 Fuzzy Logic Control: Theory and Applications. New York, NY, USA: Wiley/IEEE Press, 2014.
[24] G. G. Sundarkumar and V. Ravi, "A novel hybrid undersampling method for mining unbalanced datasets in banking and insurance," Eng. Appl. Artif. Intell., vol. 36, pp. 368­377, 2015.
[25] M. Antonelli, P. Ducange, and F. Marcelloni, "Multi-objective evolutionary rule and condition selection for designing fuzzy rule-based classifiers," in Proc. IEEE Int. Conf. Fuzzy Syst., Brisbane, Australia, Jun. 10­15, 2012, pp. 794­800.
[26] M. Antonelli, P. Ducange, and F. Marcelloni, "A fast and efficient multiobjective evolutionary learning scheme for fuzzy rule-based classifiers," Inf. Sci., vol. 283, pp. 36­54, 2014.
[27] M. Antonelli, P. Ducange, and F. Marcelloni, "An experimental study on evolutionary fuzzy classifiers designed for managing imbalanced datasets," Neurocomput., vol. 146, pp. 125­136, 2014.
[28] J. Alcala-Fdez, R. Alcala, and F. Herrera, "A fuzzy association rulebased classification model for high-dimensional problems with genetic rule selection and lateral tuning," IEEE Trans. Fuzzy Syst., vol. 19, no. 5, pp. 857­872, Oct. 2011.
[29] J. Huhn and E. Hullermeier, "FURIA: An algorithm for unordered fuzzy rule induction," Data Mining Knowl. Discovery, vol. 19, no. 3, pp. 293­ 319, 2009.
[30] J. Quinlan, C4.5: Programs for Machine Learning. San Mateo, CA, USA: Morgan Kauffman, 1993.
[31] K. M. Ting, "An instance-weighting method to induce cost-sensitive trees," IEEE Trans. Knowl. Data Eng., vol. 14, no. 3, pp. 659­665, May/Jun. 2002.
[32] Q. Liang and J. M. Mendel, "Interval type-2 fuzzy logic systems: Theory and design," IEEE Trans. Fuzzy Syst., vol. 8, no. 5, pp. 535­550, Oct. 2000.
[33] D. Bernardo, H. Hagras, and E. Tsang, "An interval type-2 fuzzy logic system for the modelling and prediction of financial applications," presented at the Int. Conf. Auton. Intell. Syst., Aveiro, Portugal, Jun. 25­27, 2012.
[34] D. Bernardo, H. Hagras, and E. Tsang, "An interval type-2 fuzzy logic based system for model generation and summarization of arbitrage opportunities in stock markets," presented at the U.K. Workshop Comput. Intell., Edinburgh, U.K., Sep. 5­7, 2012.
[35] D. Bernardo, H. Hagras, and E. Tsang, "A genetic type-2 fuzzy logic based system for financial applications modelling and prediction," presented at the Proc. IEEE Int. Conf. Fuzzy Syst., Hyderabad, India, Jul. 7­10, 2013.
[36] A. Zhou, B-Y. Qu, H. Li, S-Z. Zhao, P. N. Suganthan, and Q. Zhang, "Multiobjective evolutionary algorithms: A survey of the state of the art," Swarm Evol. Comput., vol. 1, no. 1, pp. 32­49, 2011.

ANTONELLI et al.: MULTIOBJECTIVE EVOLUTIONARY OPTIMIZATION OF TYPE-2 FUZZY RULE-BASED SYSTEMS

263

[37] P. Ducange, B. Lazzerini, and F. Marcelloni, "Multi-objective genetic fuzzy classifiers for imbalanced and cost-sensitive datasets," Soft Comput., vol. 14, no. 10, pp. 713­728, 2010.
[38] F. Herrera, "Genetic fuzzy systems: Taxonomy, current research trends and prospects," Evol. Intell., vol. 1, no. 1, pp. 27­46, 2008.
[39] J. M. Alonso and L. Magdalena, "Editorial: Special issue on interpretable fuzzy systems," Inf. Sci., vol. 181, no. 20, pp. 4331­4339, 2011.
[40] M. J. Gacto, R. Alcala´, and F. Herrera, "Interpretability of linguistic fuzzy rule-based systems: An overview of interpretability measures," Inf. Sci., vol. 128, no. 20, pp. 4340­4360, 2011.
[41] M. Cococcioni, P. Ducange, B. Lazzerini, and F. Marcelloni, "A Paretobased multi-objective evolutionary approach to the identification of mamdani fuzzy systems," Soft Comput., vol. 11, no. 11, pp. 1013­1031, 2007.
[42] A. Botta, B. Lazzerini, F. Marcelloni, and D. Stefanescu, "Context adaptation of fuzzy systems through a multi-objective evolutionary approach based on a novel interpretability index," Soft Comput., vol. 13, no. 5, pp. 437­449, 2009.
[43] R. Alcala´, P. Ducange, F. Herrera, B. Lazzerini, and F. Marcelloni, "A multi-objective evolutionary approach to concurrently learn rule and data bases of linguistic fuzzy rule-based systems," IEEE Trans. Fuzzy Syst., vol. 17, no. 5, pp. 1106­1122, Oct. 2009.
[44] M. Antonelli, P. Ducange, B. Lazzerini, and F. Marcelloni, "Multi-objective evolutionary learning of granularity, membership function parameters and rules of Mamdani fuzzy systems," Evol. Intell., vol. 2, no. 1­2, pp. 21­37, 2009.
[45] J. Casillas, P. Martinez, and A. D. Benitez, "Learning consistent, complete and compact sets of fuzzy rules in conjunctive normal form for regression problems," Soft Comput., vol. 13, no. 5, pp. 451­465, 2009.
[46] P. Pulkkinen and H. Koivisto, "A dynamically constrained multiobjective genetic fuzzy system for regression problems," IEEE Trans. Fuzzy Syst., vol. 18, no. 1, pp. 161­177, Feb. 2010.
[47] M. Antonelli, P. Ducange, B. Lazzerini, and F. Marcelloni, "Learning concurrently data and rule bases of Mamdani fuzzy rule-based systems by exploiting a novel interpretability index," Soft Comput., vol. 15, no. 10, pp. 1981­1998, 2011.
[48] M. Antonelli, P. Ducange, B. Lazzerini, and F. Marcelloni, "Learning knowledge bases of multi-objective evolutionary fuzzy systems by simultaneously optimizing accuracy, complexity and partition integrity," Soft Comput., vol. 15, no. 12, pp. 2335­2354, 2011.
[49] M. J. Gacto, R. Alcala, and F. Herrera, "Integration of an index to preserve the semantic interpretability in the multi-objective evolutionary rule selection and tuning of linguistic fuzzy systems," IEEE Trans. Fuzzy Syst., vol. 18, no. 3, pp. 515­531, Jun. 2010.
[50] R. Alcala´, M. J. Gacto, and F. Herrera, "A fast and scalable multiobjective genetic fuzzy system for linguistic fuzzy modeling in high-dimensional regression problems," IEEE Trans. Fuzzy Syst., vol. 19, no. 4, pp. 666­681, Aug. 2011.
[51] M. Antonelli, P. Ducange, and F. Marcelloni, "Genetic training instance selection in multi-objective evolutionary fuzzy systems: A co-evolutionary approach," IEEE Trans. Fuzzy Syst., vol. 20, no. 2, pp. 276­290, Apr. 2012.
[52] H. Ishibuchi, T. Murata, and I. B. Turksen, "Single-objective and two objective genetic algorithms for selecting linguistic rules for pattern classification problems," Fuzzy Sets Syst., vol. 89, no. 2, pp. 135­150, 1997.
[53] O. Cordon, M. J. del Jesus, J. Casillas, F. Herrera, L. Magdalena, and P. Villar, "A multiobjective genetic learning process for joint feature selection and granularity and context learning in fuzzy rule-based classification systems," in Interpretability Issues in Fuzzy Modeling, J. Casillas, F. Herrera, O. Cordoon, and L. Magdalena, Eds. Secaucus, NJ, USA: Springer-Verlag, 2003, pp. 79­99.
[54] H. Ishibuchi and T. Yamamoto, "Fuzzy rule selection by multi-objective genetic local search algorithms and rule evaluation measures in data mining," Fuzzy Sets Syst., vol. 141, pp. 59­88, 2004.
[55] H. Ishibuchi and Y. Nojima, "Analysis of interpretability-accuracy tradeoff of fuzzy systems by multiobjective fuzzy genetics-based machine learning," Int. J. Approx. Reason., vol. 44, no. 1, pp. 4­31, 2007.
[56] R. Alcala´, Y. Nojima, F. Herrera, and H. Ishibuchi, "Multiobjective genetic fuzzy rule selection of single granularity-based fuzzy classification rules and its interaction with the lateral tuning of membership functions," Soft Comput., vol. 15, no. 12, pp. 2303­2318, 2011.
[57] P. Pulkkinen and H. Koivisto, "Fuzzy classifier identification using decision tree and multiobjective evolutionary algorithms," Int. J. Approx. Reason., vol. 48, pp. 526­543, 2008.

[58] K. Trawinski, O. Cordon, and A. Quirin, "A Study on the use of multiobjective genetic algorithms for classifier selection in FURIA-based fuzzy multiclassifiers," Int. J. Comput. Intell. Syst., vol. 5, no. 2, pp. 231­253, 2012.
[59] O. Cordon, M. J. del Jesus, and F. Herrera, "A proposal on reasoning methods in fuzzy rule-based classification systems," Int. J. Approx. Reason., vol. 20, no. 1, pp. 21­45, 1999.
[60] W. W. Cohen, "Fast effective rule induction," in Proc. 12th Int. Conf. Mach. Learning, 1995, pp. 115­123.
[61] J. R. Quinlan, "Boosting, bagging, and C4.5," in Proc. 13th Nat. Conf. Artif. Intell., 1996, vol. 1, pp. 725­730.
[62] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, "Smote: Synthetic minority over-sampling technique," J. Artif. Intell. Res., vol. 16, pp. 321­357, 2002.
[63] J. Alcala-Fdez, A. Fernandez, J. Luengo, J. Derrac, and S. Garcia, "KEEL data-mining software tool: Data set repository, integration of algorithms and experimental analysis framework," Multiple-Valued Log. Soft Comput., vols. 2/3, pp. 255­287, 2011.
[64] T. Fawcett, "An introduction to ROC analysis," Pattern Recog. Lett., vol. 27, no. 8, pp. 861­874, 2006.
[65] M. Friedman, "The use of ranks to avoid the assumption of normality implicit in the analysis of variance," J. Amer. Stat. Assoc., vol. 32, pp. 675­ 701, 1937.
[66] R. L. Iman and J. H. Davenport, "Approximations of the critical region of the Friedman statistic," Commun. Statist. A, Theory Methods, vol. 9, pp. 571­595, 1980.
[67] S. Holm, "A simple sequentially rejective multiple test procedure," Scand. J. Statist., vol. 6, pp. 65­70, 1979.
[68] D. J. Sheskin, Handbook of Parametric and Nonparametric Statistical Procedures, 4th ed. London, U.K.: Chapman & Hall/CRC Press, 2007.
Michela Antonelli received the M.Sc. degree in computer engineering and the Ph.D. degree in information engineering from the University of Pisa, Pisa, Italy, in 2003 and 2007, respectively.
She was a Research Fellow with the Computational Intelligence Group, Department of Information Engineering, University of Pisa, from 2008 to 2014. She is currently a Research Associate with the Centre for Medical Image Computing, University College London, London, U.K. Her main research interests include computational intelligence, with particular emphasis to fuzzy systems and multiobjective evolutionary algorithms.
Dario Bernardo received the B.Sc. and M.Sc. degrees in computer engineering for enterprise management from the University of Pisa, Pisa, Italy, and another M.Sc. degree in computational and software techniques in engineering from Cranfield University, Cranfield, U.K. He is currently working toward the Ph.D. degree in computer science with the University of Essex, Colchester, U.K., as a Knowledge Partnership Associate.
He is currently a Data Scientist working in London, U.K., in the field of predictive analytics in finance. His major research interests include computational intelligence, machine learning, type-2 fuzzy systems, fuzzy logic, genetic algorithms, and evolutionary computation. His research interests also include big data analytics, algorithm scalability, and optimization.

264

IEEE TRANSACTIONS ON FUZZY SYSTEMS, VOL. 25, NO. 2, APRIL 2017

Hani Hagras (M'03­SM'05­F'13) received the B.Sc. and M.Sc. degrees in electrical engineering from Alexandria University, Alexandria, Egypt, and the Ph.D. degree in computer science from the University of Essex, Colchester, U.K.
He is currently a Professor with the School of Computer Science and Electronic Engineering, Director of the Computational Intelligence Centre, and the Head of the Fuzzy Systems Research Group with the University of Essex. His major research interests include computational intelligence, notably type-2 fuzzy systems, fuzzy logic, neural networks, genetic algorithms, and evolutionary computation. His research interests also include ambient intelligence, pervasive computing, and intelligent buildings. He is also interested in embedded agents, robotics, and intelligent control. He has authored more than 300 papers in international journals, conferences, and books. Dr. Hagras is a Fellow of the Institution of Engineering and Technology. He was the Chair of IEEE Computational Intelligence Society (CIS) Senior Members Subcommittee. He has received numerous prestigious international awards where most recently he was awarded by the IEEE CIS the 2013 Outstanding Paper Award in the IEEE TRANSACTIONS ON FUZZY SYSTEMS. He also received the 2006 Outstanding Paper Award in the IEEE TRANSACTIONS ON FUZZY SYSTEMS. He is an Associate Editor of the IEEE TRANSACTIONS ON FUZZY SYSTEMS. He is also an Associate Editor of the International Journal of Robotics and Automation, the Journal of Cognitive Computation, and the Journal of Ambient Computing and Intelligence. He is a member of the IEEE CIS Fuzzy Systems Technical Committee and IEEE CIS Conference Committee. He chaired several international conferences where he will act as the Programme Chair of the 2017 IEEE International Conference on Fuzzy Systems, Naples, Italy, July 2017, and he served as the General Co-Chair of the 2007 IEEE International Conference on Fuzzy Systems, London, U.K.

Francesco Marcelloni (M'06) received the Laurea degree in electronics engineering and the Ph.D. degree in computer engineering from the University of Pisa, Pisa, Italy, in 1991 and 1996, respectively.
He is currently a Full Professor with the Department of Information Engineering, University of Pisa. He has co-founded the Computational Intelligence Group in 2002 and is the Founder and Head of the Competence Centre on MObile Value Added Services (MOVAS), both with the Department of Information Engineering, University of Pisa. His main research interests include fuzzy classifiers for big data, multiobjective evolutionary algorithms, genetic fuzzy systems, fuzzy clustering algorithms, pattern recognition, signal analysis, neural networks, mobile information systems, and data compression and aggregation in wireless sensor networks. He has coedited three volumes, four journal special issues, and is (co)author of a book and of more than 200 papers in international journals, books, and conference proceedings. He has been TPC co-chair, general co-chair, and tutorial chair of some international conferences and has held invited talks in a number of events. Dr. Marcelloni is an Associate Editor of Information Sciences (Elsevier) and Soft Computing (Springer). He is on the Editorial Board of a number of other international journals.



