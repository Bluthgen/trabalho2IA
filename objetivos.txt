The alternatives we have developed the above ranking approach for are stock exchange traded equities . 

We have considered application to a developing financial market and are currently extending the application to comparison of performance in developing and developed financial markets . 

B. Interval Type-2 Fuzzy Number Implementation In this implementation of FN-TOPSIS , we use interval type-2 fuzzy number , as detailed in Tables IVГVI , for rating of alternatives and weighting the importance of criteria . 

RANKING OF TRADED EQUITY We study the problem of ranking traded equity in developing financial markets within a crisis period , in order to illustrate the applicability and validity of the proposed FN methodology in a realistic scenario . 

Rule 1 : If BL is VG and CL is VG , then EL is VG Rule 2 : If BL is VG and CL is VG , then EL is VG ... ... ... Rule 25 : If BL is G and CL is G , then EL is G. Step 8 : Having list of rules for three systems -- BS , CS , ES -- we now present these rules in the Boolean matrix form . 

We have successfully applied FN-TOPSIS to the problem of ranking equities traded in a developing financial market during a crisis period . 

We are interested in the following : 1 ) modelling the dynamics of these risk averse agents and 2 ) sequential detection of a market shock based on the behaviour of these agents . 

Digital Object Identifier 10.1109/JSTSP.2016.2548995 In this paper , we are interested in developing agent based models for studying global events in financial markets where the underlying value of the stock experiences a jump change ( shock ) . 

This paper considers a similar model , but , in order to incorporate property 3 above ( risk averse behaviour ) , we will replace the classical social learning model of expected cost minimizers with that of risk averse minimizers . 

We consider social learning under CVaR risk measure . 

We show that , under reasonable assumptions on the costs , the trading decisions taken by socially aware and risk-averse agents are ordinal functions of their private observations and monotone in the prior information . 

We show that the stopping region for the sequential detection problem is non-convex ; this is in contrast to standard signal processing quickest detection problems where the stopping set is convex . 

We use a data set from Tech Buzz Game which is a stock 1A risk measure : L R is a mapping from the space of measurable functions to the real line which satisfies the following properties : ( i ) ( 0 ) = 0 . 

We assume that the price is the same during the period in which the value changes . 

We introduce a model predictive controller ( MPC ) and a proportional-integralderivative ( PID ) controller , and compare them with a benchmark method employed in finance and economics , stochastic dynamic programming ( DP ) . 

models of financial resource allocation between risky and risk-less assets of Merton [ 4 ] and Samuelson [ 17 ] , and their subsequent improvements that introduced various constraints , we propose a discrete time multiple input multiple output stochastic model with state-dependent constraints that reflect income uncertainties , investments , risks , liquidity , and credit constraints for underprivileged households . 

We also consider that the current assets are employed to fund consumption and all transactions that require cash , and that the sale of fixed assets is done without cost or time delay . 

C. Objective Function With this model , we will try to develop controllers that help the agent to build savings that will make him/her more resilient to shocks and uncertainty . 

Our goal is not to model the agent 's behavior by employing cost functions , such as the constant relative risk aversion utility function or other standard isoelastic cost function [ 18 ] ; instead , we seek to minimize a running quadratic cost over a finite horizon with target states x R2 and controls u U g ( x , u ) = |x ( k ) -x |T Q|x ( k ) -x |+|u ( k ) -u|T R|u ( k ) -u| . 

1 ) Formulation : As the PID controller does not explicitly consider the minimization of a cost function in its usual form , we build a reference vector r ( k ) , where the reference trajectories are ramps from the initial condition x0 to the desired values x with given slopes for each state , denoted by the vector S. The goal of the controller will be to drive the error e ( k ) = r ( k ) - x ( k ) to zero , where the reference vector r ( k ) is r ( k ) = min { x0 + k S , x } . 

We define a PID controller as the feedback law correspond- ing to each input ui ( k ) for i { 1 , 2 , 3 } . 

We develop a `` projection algorithm '' to ensure that the control input remains in the feasible set Uk . 

We report a cointegration between the returns of the S & P 500 index and its intrinsic value . 

We propose a network of bargaining agents [ 35 ] ­ [ 39 ] along with the competition and cooperation mechanisms between them [ 40 ] ­ [ 43 ] . 

We demonstrate how the degree of market overpricing through a feedback mechanism between trading and price dynamics induces further market overpricing , market bubbles , and ultimately market collapse [ 25 ] , [ 44 ] ­ [ 47 ] . 

We find that a well-known US financial index , the S & P 500 index , exhibits a hysteresis behavior , as well as market-collapse tipping points and recovery tipping points that confirm the predictions of our network model . 

We report that the model , with only the change in the S & P 500 intrinsic value as input , consistently generates prices which exhibit appropriate heavy-tailed drawdown and drawup distributions . 

We propose a coupled network model composed of equally sized demand ( buyer ) and supply ( seller ) networks , where agents represented as network nodes , cooperate with agents on the opposite side of the market [ 43 ] , but compete with agents on the same side of the market , as depicted in Fig . 

The first two are the trivial cases of the network model , and the last case is representative of the networks in our model , since the values of p are non-trivial and vary as defined in equation ( 3 ) . 

We define this ratio R = S ( t ) SI ( t ) between the market price S and and the intrinsic value SI as the Market-to-Intrinsic ratio . 

Our model for determining the intrinsic value is based on the widely used free cash flow model ( FCFM ) [ 55 ] , [ 56 ] , in which the stock of a company is worth the sum of all of SI ( t ) = j=1 F CFt+j j k=1 ( 1 + W AC Ct + k ) ( 8 ) and the discount rate is the future weighted average cost of capital ( WACC ) . 

The SI value is approximate because for the t - T time period we know only those FCF and WACC values from t - T up to time t and thus the FCF and WACC values for times longer than t must be estimated . 

Our model model has two stages , a volatile growth phase that lasts T years followed by a stable `` steady state '' growth phase . 

We first examine the steady state growth phase where the ultimate question to be answered is : what are the dynamics that control cash flow ? 

This accumulated collective uncertainty among agents we quantify as the variance of model price , and Fig . 

We also show the average clustering coefficients ( calculated as the mean of local clustering coefficients of all vertices , as proposed by [ 59 ] ) for the supply and demand networks , shown in Fig . 

4 ( a ) ­ ( b ) are in agreement with a complex system phenomenon called critical slowing down [ 11 ] characterized by the increase in the variance as the system approaches criticality , which is , in our case , market collapse . 

5 ( a ) further validates our intrinsic price since we find that the peaks of the market-to-intrinsic ratio follow the peaks of the Shiller P/E indicator widely used to estimate the degree of market overpricing . 

This fact affirms that our SI represents a reasonable estimation of the intrinsic value of the S & P 500 index . 

We confirm the intriguing possibility that two distinct underpriced and overpriced modes are present in the financial complex system . 

We apply a statistical mixture model to reveal the presence of a substructure in the ratio and show that the probability distribution function of the ratio fits the Gaussian mixture model , which resembles the bimodal shape characteristic for small nonlinear systems near a tipping point [ 61 ] . 

Note that we can locate this substructure of the financial system with the underpriced and overpriced modes because we have a model that can estimate the intrinsic price . 

We quantify this assumption by investigating the long-term relationship [ 62 ] between the S & P 500 index , SM ( t ) , and the intrinsic value of the S & P 500 index , SI ( t ) , i.e . 

The multiscale sample entropy and our proposed Assessment of Latent Index of Stress methods have successfully assessed financial stress , and have served as a measure to establish an analogy between transitions from ` normal ' ( relaxed ) to ` abnormal ' ( stressed ) financial periods with the sympatho-vagal balance in humans . 

Our findings support the EMH theory and reveal high stress for both the periods of Internet bubble burst and sub-prime mortgage crisis . 

It is therefore natural to ask whether a general health of the economy , seen through the lens of stock indices , can be assessed in a way analogous to the way we examine health of living organisms . 

Our analysis falls under this general umbrella , but is finance-specific and employs nonparametric analyses of the determinism ( via predictability ) , nonlinearity , multiscale entropy , and synchrony , within an intrinsic multivariate analysis framework . 

Our approach falls between these two categories -- it is composite in the sense that it simultaneously analyses several individual market indices , while being specific enough to examine the balance/imbalance aspect of markets . 

Our rationale is that low-frequency changes ( LF band ) , which correspond to time spans of over 1 year , are driven by global factors ( monetary policies ) , whereas the more rapid changes ( HF band ) , over spans of 5 days to 3 months , signify abrupt events , such as the 9/11 crisis and the Internet bubble burst . 

SUMMARY OF MOTIVATION AND CONTRIBUTION Inspired by the catastrophe theory [ 22 ] and the EMH theory , we propose the ALIS index as an indicator of financial stress during episodes of financial crises in different individual stock indices . 

We also introduce the moving-average multivariate sample entropy ( MA-MSE ) algorithm to quantify different degrees of such complexity . 

We also consider four financial markets outside the US in order to assess the performance of the ALIS : ( i ) Financial Times Stock Exchange 100 ( FTSE 100 ) , ( ii ) Cotation Assiste´e en Continu 40 ( CAC 40 ) , ( iii and iv ) foreign exchange ( Forex ) markets for the EUR/GBP and GBP/JPY . 

ALGORITHM AND BACKGROUND We shall first briefly describe the algorithms used in this study . 

We here introduce its variate , termed MA-MSE , to quantify multivariate complexity of both the trend and the detrended data , a procedure referred to as the MA-MSE , outlined in Algorithm 1 . 

Financial time series contain different degrees of volatility , or in other words power imbalances among the signal channels ; therefore in the intrinsic multiscale analysis we use the noiseassisted adaptive-projection intrinsically-transformed MEMD ( NA-APIT-MEMD ) which accounts for the different dynamics in multivariate data ( see [ 43 ] for more detail ) . 

F. Assessment of Latent Index of Stress ( ALIS ) We shall now introduce the ALIS to quantify ` stress level of a financial organism ' by considering the detrended data , zk , j , as the input , followed by aggregating the normalised financial time series of the low ( 0­0.0042 Hz , LF ) and high ( 0.0167­ 0.2 Hz , HF ) frequency bands . 

We tested our approach , named IT2-PAES-RCS , on 11 financial datasets and compared our results with the ones obtained by the original PAES-RCS with three objectives and with and without scaled dominance , the FRBCs , fuzzy association rule-based Manuscript received June 26 , 2015 ; revised September 18 , 2015 and January 21 , 2016 ; accepted April 20 , 2016 . 

Another reason why it is important that we can understand models is trust . 

We denote this extension as IT2-PAES-RCS in the following . 

We modified both the inference mechanism and the evolutionary process for coping with the IT2 fuzzy sets . 

We tested IT2-PAES-RCS on 11 financial datasets and compared the results with the ones obtained by the original PAES-RCS , employing FPR and TPR as objectives , with ( PAES-RCS-SD ) and without scaled dominance , the FRBCs fuzzy association rule-based classification model for highdimensional dataset ( FARC-HD ) [ 28 ] and fuzzy unordered rules induction algorithm ( FURIA ) [ 29 ] , the classical C4.5 decision tree algorithm [ 30 ] , and its cost-sensitive version ( C4.5-CS ) [ 31 ] . 

We recall that an IT2 fuzzy set A~ is characterized by a fuzzy membership function A~ ( x ) , that is , the membership value for each element of this set is a fuzzy set [ 32 ] . 

We build the IT2 fuzzy sets by using the following procedure . 

First of all , we employ IT2 fuzzy sets rather than type-1 fuzzy sets . 

We recall that TPR and FPR coincide , respectively , with the sensitivity and the complement to 1 of the specificity . 

Third , we use an approach denoted as scaled dominance , which was introduced in [ 33 ] ­ [ 35 ] , to handle unbalanced data by trying to give minority classes a fair chance when competing with a majority class . 

Initial Rule Base Generation We generate the initial rule base by first transforming each continuous variable into a categorical and ordered variable . 

We extract the initial rule base from the decision tree generated by the C4.5 algorithm . 

We observe that only three out of the six original input variables are included in the decision tree . 

We note that the rule base consists of 13 rules , which correspond to the 13 possible paths from the root to the leaf nodes . 

We note that , even though Mmax = 3 , only two rules have been selected in the final rule base . 

It is necessary to note that in this paper , we assume all the emer- gencial incidents are mutually exclusive event ( i.e. , when the jump occurs at time instant t , there is only one mark k to be assigned ) . 

1 , we want to design a multiobjective H2 /H robust investment policy for system state x ( t ) to achieve a desired state xd from the perspective of minimum H2 regulation error with minimum investment effort u ( t ) in ( 6 ) and minimum H investment risk in ( 7 ) under intrinsic fluctuations and external disturbance . 

Lemma 4 ( see [ 18 ] ) : For any matrix Mi with appropriate di- mension and the scheduling functions hi ( z ) with 0 hi ( z ) 1 , for i N+ , 1 i m , P > 0 , and m i=1 hi ( z ) = 1 , we have T l hj ( z ) Mj P j=1 l hi ( z ) Mi i=1 l hi ( z ) MiT P Mi . 

We will show this by contradiction . 

We derive the sufficient condition for J2 ( u ( t ) ) of the MOP in ( 18 ) first . 

Proof : Since the given Lyapunov function V ( x~ ( t ) ) = x~T ( t ) P x~ ( t ) is satisfied with the following two inequalities : m1 x~ ( t ) 2 2 V ( x~ ( t ) ) m2 x~ ( t ) 2 2 ( 37 ) where m1 > 0 and m2 > 0 , by the Ito^ГLe┤vy formula of V ( x~ ( t ) ) in ( 9 ) and the fact that u ( t ) is a feasible solution of the LMI- constrained MOP in ( 19 ) , we obtain dE { V ( x~ ( t ) ) } = E { dV ( x~ ( t ) ) } = E { ( 2x~T ( t ) P f ( x~ ( t ) ) m + 2x~T ( t ) P Bu ( t ) + T ( x~ ( t ) ) P ( x~ ( t ) ) + k k=1 [ V ( x~ ( t ) + ( x~ ( t ) , k ) ) - V ( x~ ( t ) ) ] ) dt } E -x~T ( t ) Q1 x~ ( t ) dt E -m3 x~ ( t ) 2 2 dt -m3 E { V ( x~ ( t ) ) } dt < 0 ( 38 ) m2 where m3 is the smallest eigenvalue value of positive-definite matrix Q1 > 0 . 

m1 m1 m2 ( 40 ) It is obvious that lim E t - x~ ( t ) 2 2 =0 and we obtain lim x~ ( t ) = 0 exponentially in the mean square sense . 

H2/H investment policy problem of nonlinear stochastic jump Remark 2 : In this study , we use the 3-D nonlinear stochas- diffusion financial system , the MOP in Theorems 1 and 3 with tic financial system to illustrate the proposed multiobjective LMI constraints to guarantee the robust stability of nonlinear H2/H investment theories . 

V. SIMULATION RESULTS To illustrate the design procedure and to confirm the performance of the proposed optimal investment policy for nonlinear stochastic jump diffusion financial system , we introduce a nonlinear stochastic jump diffusion financial system to mimic an emerging market in ( 2 ) . 

We also present the model estimation methods for the GPRSV model . 

We demonstrate the superior volatility prediction performance of our model with both simulated and empirical financial data . 

propose the Gaussian process dynamical model ( GPDM ) in [ 22 ] . 

propose the PGAS algorithm . 

propose a GP based GARCH model and a regularized auxiliary particle chain filter ( RAPCF ) algorithm to estimate the model . 

We apply the recent development of Bayesian nonparametric methods to improve the prediction performance of volatility models . 

We estimate the hidden states or system variable distribution by taking a full Bayesian nonparametric approach . 

We can use two estimation methods for the new model . 

We demonstrate the superior volatility prediction performance of the new GPRSV model and inference methods with both simulated and empirical financial data . 

Our main contribution is to introduce a novel nonparametric model -- GPRSV model to solve the problem of modeling and predicting time-varying variance of financial time series data . 

The second contribution of work is that we provided a solution to learn the proposed model . 

We demonstrate that both SMC algorithms such as RAPCF [ 28 ] and MCMC algorithms such as PGAS [ 19 ] can be adjusted to estimate the GPRSV models . 

We also demonstrated through experiments that the new GPRSV model performs better than corresponding GARCH and SV models . 

Volatility is a forward-looking concept , we often model the financial time series return variance conditioned on all the relevant information It-1 , defined as t2 = var ( rt |It-1 ) = E ( ( rt - t ) 2 |It-1 ) ( 3 ) where t is expected value of the asset return rt . 

GPRSV MODEL We introduce a new GPRSV model to solve the problem of financial time series volatility modeling and predicting . 

The logarithm of variance is modeled as the unobserved latent variable of the system in our model . 

We use GP to sample unknown hidden states transition function . 

We assume the hidden state transition function f is sampled from a GP . 

We can take advantage of this tool to more accurately predict time-varying volatilities . 

We assume that the hidden system state process is governed by a stationary stochastic process . 

We can put all hyper-parameters in a vector . 

We use logarithm of variance instead of standard deviation directly in our model . 

E. Model Building Process We can build a GPRSV model in a four step process similar to Tsay 's procedures in [ 7 ] of building a traditional conditional volatility model . 

We show the flowchart of this process in Fig . 

1 ) Specify Mean Equation : First we need to test the serial dependence in the return series . 

We define T SSR0 = ( at2 - Ż ) 2 , t=m+1 ( 11a ) T SSR1 = c^t2 , t=m+1 ( 11b ) F = ( SSR0 - SSR1 ) /m , SSR1 / ( T-2m - 1 ) ( 11c ) where T Ż = ( 1/T ) a2t ( 12 ) t=1 is the sample mean of at2 ; F is asymptotically distributed as a chi-squared distribution m2 under null hypothesis and m is the degree of freedom . 

4 ) Estimate Model Parameters and Check Model Fitness : After specifying both the mean and volatility equations , and associated hyper-parameters and in Steps 2 and 3 , we can use training data to estimate unknown parameters . 

We can examine the model fitness using the diagnostics of the SV model described by Kim et al . 

This paper follows on from our previous work on the trade-based manipulation [ 2 ] and proposes a detection approach that considers a complete spectrum of the wash trade detection . 

The 125 and 125.5 are the execution prices of the two possible transactions ; we refer to such prices as transaction prices . 

B. Wash Trade Detection To the best of our knowledge , there is no related work on the detection of wash trade activities in capital markets . 

We merge the potential transactions who price margins are overlapped , i.e. , 125 + 0.8 and 125.5 + 0.5 are overlapped . 

We utilize this idea in [ 25 ] and represent submitted limit orders ( from a number of traders ) by a graph , where vertices represent traders , and the short arrows affixed to the vertex represent the orders submitted by the trader ( buying and the selling orders are represented by arrows pointing inward and outward , respectively ) and the dotted arrow lines represent the possible executed orders according to the matching rule discussed in Section II-A . 

The main principles of dynamic programming are that we have to come up with a number of subproblems so that each subproblem can be solved easily from smaller subproblems , and the solution of the original problem can be obtained easily once we know the solutions to all the subproblems [ 30 ] . 

The recursion can then be summarized as follows : if L N is not one of the orders in the final subset SN , we can ignore the order N and determine OPT ( N - 1 , Vk ) ; however , if L N is one of the orders , we need to seek an optimal solution for the remaining orders , 1 , . 

We consider the case of constant interest rates ri and constant volatilities i . 

Section II presents the basis for our generic model and the schemes for its ( approximate ) simulation . 

Section III then presents our GPE and the various inputs ( user-defined formulae , etc . ) 

Section IV discusses a range of stochastic processes where our GPE can give an exact simulation . 

We use Eq . 

A GENERIC PRICING ENGINE We use Glasserman 's equation , Eq . 

We consider a load serving entity ( LSE ) , such as an electrical distribution utility , that holds a service obligation to supply electricity at the predetermined hour without restriction on volume ( a load following contract ) . 

PROBLEM FORMULATION We consider the dataset D = { yP , i , y , i , Zi } iN=1 , ( 1 ) where scalars yP , i and y , i are response variables , vectors Zi n are explanatory variables ( regressors ) , i is the sample number , and N is the number of the samples . 

We are trying to estimate the probability density p ( y|Zi ) from data ( 6 ) . 

We assume that the distribution p ( y|Z ) for ( 6 ) is described by the following QR model P ( y y ( q ) |Z ) = q , ( 7 ) y ( q ) = Z ( q ) + ( q ) , ( 8 ) where q ( 0 , 1 ) is the quantile level ; n and are the QR hyperplane parameters . 

Multiple Quantile Regression We need a model of the form ( 7 ) , where = ( q ) and = ( q ) are smooth functions that can be differentiated to compute the probability density . 

A scalable approach to solving problem ( 11 ) is discussed in our paper [ 35 ] , where more detail can be found . 

We assume the tail probability distributions to be Z1 + 1 - y|y < Z1 + 1 Exp ( L ) , ( 18 ) y - Zm - m |y > Zm + m Exp ( R ) . 

We extended this model to the entire ( 0 , 1 ) quantile interval as m y ( s|Z ) = ( Zj + j ) Kj ( s ) , ( 22 ) j=1 where kernel functions Kj ( s ) are such that Kj ( qj ) = 1 , and Kj ( qk ) = 0 for k = j . 

We use Kj ( s ) = Bj,2 ( s ) for qL s qR , ( 23 ) K1 ( s ) = L-1 log s qL for 0 < s < qL , ( 24 ) Km ( s ) = -R-1 log 1-s 1 - qR for qR < s < 1 , ( 25 ) where Bj,2 ( s ) are the second-order ( triangular ) B-spline kernels with knots ( 10 ) . 

The tail integrals for the eight edge blocks can be expressed through the following auxiliary functions qL L ( r , q ) = ( r , q ) ˇ ( q ) dq , ( 38 ) min ( q , qL ) 1 R ( r , q ) = ( r , q ) ˇ ( q ) dq , ( 39 ) max ( q , qR ) rL gL ( q ) = ( r , q ) dr , ( 40 ) 0 1 gR ( q ) = ( r , q ) dr. ( 41 ) rR Using notation ( 38 ) ­ ( 41 ) we have rL FL , L ( q ) = L ( r , q ) dr , ( 42 ) 0 rL FL , R ( q ) = R ( r , q ) dr , ( 43 ) 0 1 FR , L ( q ) = L ( r , q ) dr , ( 44 ) rR 1 FR , R ( q ) = R ( r , q ) dr , ( 45 ) rR m L ( q ) = q wi ( 1 ) L ( ri , q ) , ( 46 ) i=1 m R ( q ) = q wi ( 1 ) R ( ri , q ) , ( 47 ) i=1 m L ( q ) = q wj ( j ) gL ( qj ) ( qj ) , ( 48 ) j=j m R ( q ) = q wj ( j ) gR ( qj ) ( qj ) . 

This means in ( 32 ) , ( 33 ) we have ( y ) = exp ( ˇ y ) , ( 50 ) ( yP ) = exp ( ˇ yP ) , ( 51 ) where and are fixed exponent parameters . 

We consider the following stylized problem . 

We split up the dataset into two parts , the training and test set . 

We consider the day-ahead forward contract entered at the midnight for the electricity delivery at given hour t of the next day . 

We then used formulas ( 4 ) and ( 5 ) . 

We compute the actual realized cost Ut for the procured log power yŻP , t = yP ( so ( t ) ) , where so ( t ) minimizes the total cost Tt ( s ) in ( 72 ) . 

We compare it with the results for the baseline advance procurement policy yŻP , t = y^P , t that is based on the OLS forecast ( 68 ) , ( 69 ) . 

We backtest the optimized procurement policy yŻP , t = yP ( so ( t ) ) and the baseline OLS forecast procurement policy yŻP , t = y^P , t . 

We propose a two-regime mean-reverting model for explaining the behaviour of three time series , which mirror liquidity levels for financial markets . 

We use three 1932-4553 Š 2016 IEEE . 

Each of these indices measures , as well as the liquidity of the market , something else , which is why we use all three to infer the underlying market state . 

We made contributions in terms of methodology in modelling the regime switches in a multivariate OU model and understanding the dynamics of liquidity . 

We provide economic and econometric motivations throughout this work by explicating the relevance of chosen data for market illiquidity , and the proposed model captures the joint effects of the 3 state processes . 

We aim to use hidden Markov models ( HMMs ) driving a mean-reverting process in the analysis of the joint movements of important economic indicators to forecast liquidity and illiquidity states of the financial market . 

The HMM filtering in this paper uses the measure-change approach , which avoids the forward-backward algorithm usually embedded in several filtering techniques , and hence our approach requires much less memory during computation . 

The second indicator for liquidity levels that we consider is the VIX . 

The third indicator we consider is a metric based on the evolution of the S & P 500 . 

Our work is based on similar assumptions , but instead of finding correlation between the major indicators of illiquidity , we incorporate as much information as possible into our model by simultaneously using the three market variables integrated by a set of multidimensional dynamic filters . 

Our main contribution is the development of an HMM-driven model tailored for capturing and predicting liquidity risk levels . 

Our numerical results demonstrate that the proposed model has satisfactory capacity in identifying periods of liquidity crises . 

We specify in section III the data used for the numerical estimation and prediction experiments . 

We regard the state of the underlying Markov chain as the regime of an economy ( e.g. , see Zhou and Mamon [ 38 ] ) , or more specifically a liquidity regime dependent on major factors causing economic turbulence . 

We consider d OU processes ; each process is denoted by rt ( g ) with component g { 1 , , . 

We shall make the parameters of equation ( 4 ) regimeswitching so that each component of the d-dimensional observation process can be written as rk ( g+ ) 1 = rk ( g ) e- ( g ) ( xk ) t + ( 1 - e- ( g ) ( xk ) t ) ( g ) ( xk ) + ( g ) ( xk ) 1 - e-2 ( g ) ( xk 2 ( g ) ( xk ) ) t k ( g+ ) 1 , ( 6 ) where ( g ) = ( ( 1g ) , 2 ( g ) , . 

[ 21 ] or Erlwein and Mamon [ 19 ] , we define the following quantities : k+1 Jkj+s 1x = xn-1 , ej xn , es n=1 ( 14 ) k+1 Okj +1x = xn , ej n=1 ( 15 ) k+1 Tkj+1 ( f ) x = xn-1 , ej f ( rn ) , 1 j N. ( 16 ) n=1 Equations ( 14 ) and ( 15 ) are the respective number of jumps from es to ej and the amount of time that x occupies the state ej up to k + 1 . 

The quantity Tkj+1 ( f ) is an auxiliary process that depends on the function f of the observation process ; in our case , f takes the form f ( r ) = r , f ( r ) = r2 or f ( r ) = rk+1rk . 

Other than generalising the framework in Erlwein and Mamon [ 19 ] , our contribution includes expressing recursive fil- tering equations compactly though matrix notation . 

We provide recursive filters for ck , ( J j , ix ) k , ( Oix ) k and ( T i ( f ) ( g ) x ) k. Theorem 1 : Let D be the matrix defined in ( 17 ) . 

DESCRIPTION OF DATA FOR IMPLEMENTATION To model the levels of liquidity , we use three monthly time series data covering the period of 30 April 1998­30 April Fig . 

The choice of the end-of-month time series data sets in our analysis is mainly due to convenience as they are readily available from all data sources . 

Figure 1 shows the dynamics of the TED spread for the data collected on the last day of the month ( TED-30 ) and on the 11th of each month ( TED-11 ) ; if the 11th is not a trading day we utilise the value of the previous trading day . 

The important consideration is to select a discretisation grid ( monthly in our case ) just fine enough to capture all the major economic breaks and instabilities , and without creating distortions or introducing extra noise in the data . 

The general behaviour of the data remains the same , and therefore monthly observations are appropriate for our intended application given the correct number of calculations involved in the window processing of data points . 

The data set for our filtering applications is formed by constructing a matrix with a dimension of 181 × 3 over the period 30 April 1998 ­ 30 April 2013 with the TED , VIX and MktIll in the first , second and third columns , respectively . 

Note that we use MktIll × 100 to scale the magnitude of MktIll and make it comparable to that of the TED and VIX . 

We obtain analytical option valuation expressions in crisp case . 

We also propose a method of automatized decision making , which utilizes the fuzzy valuation formulas . 

Our log-price model Y is a Levy process , which is a sum of a drifted Brownian motion and a linear combination of Poisson processes modeling jumps in the financial instrument prices . 

We apply minimal variance equivalent martingale measure ( MVEMM ) , described by Miyahara in [ 17 ] , as the equivalent martingale measure . 

This leads to a new form of the European option pricing formulas in the crisp case which , to the best of our knowledge , were not published yet . 

FUZZY ARITHMETIC -- BASIC DEFINITIONS AND FACTS For a fuzzy subset A~ of the set of real numbers R , we use the symbol A~ to denote its membership function A~ : R [ 0 , 1 ] and the symbol A~ = { x : A~ } to denote the -level set of A~ for ( 0 , 1 ] . 

We denote the -field of Borel subsets of R by B ( R ) and the set of all fuzzy numbers by F ( R ) . 

We call a fuzzy-number-valued map X~ : F ( R ) , where ( , F ) is a measurable space , a fuzzy random variable if ( , x ) : X~ ( ) ( x ) F × B ( R ) for every [ 0 , 1 ] ( see [ 34 ] for further details ) . 

We recall basic facts concerning the arithmetic of fuzzy numbers . 

We denote the binary operators between fuzzy numbers , corresponding to standard operators + , - , × , / of addition , subtraction , multiplication , and division between crisp real numbers by the symbols , , , and , respectively . 

We denote a binary operator int , int , int or int between closed intervals [ a , b ] and [ c , d ] by the symbol int . 

The following proposition , quoted from [ 20 ] , will be very useful in our pricing method . 

We apply triangular fuzzy numbers in our numerical anal- ysis of fuzzy pricing formula for the European option ( see Section VII-C ) . 

We introduce some notations and recall necessary definitions and facts concerning stochastic analysis in continuous time , including the martingale method of pricing . 

We assume that the risk-free spot interest rate is constant and we denote it by r. We use a cadlag stochastic process St , adapted to the filtration ( Ft ) , as the underlying asset 's price process . 

We also refer the reader to [ 37 ] , where characteristic triplet ( Bt , Ct , t ) was defined for quasi-left continuous semimartingales in the Hilbert space-valued case . 

We introduce the set CF = { ( f , g ) C and F ( Lt ( f , g ) ) is integrable } . 

We define the class of minimal distance martingale measures , considered in [ 17 ] . 

We will denote this measure by the symbol P ( M V E M M ) . 

